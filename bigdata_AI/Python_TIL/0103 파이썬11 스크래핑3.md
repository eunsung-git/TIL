```python
import requests
from bs4 import BeautifulSoup

soup=BeautifulSoup(res2.text, 'html.parser')
mileage=soup.select_one('#container > div > div.sm_mymileage > dl.mileage_section1 > dd > span').text
ecoin=soup.select_one('#container > div > div.sm_mymileage > dl.mileage_section2 > dd > span').text
print(mileage)
print(ecoin)

# 2,000
# 0
```

--------------------------------------------------------------------------------------------------------------------------------------------------------

웹브라우저 스크래핑     **Selenium**
pip install selenium

cmd 에서 이용하는 웹    **phantomjs**

```python
from selenium import webdriver
url='http://www.naver.com'

# phantomjs 드라이버 추출
browser=webdriver.PhantomJS()

# 3초 대기
browser.implicitly_wait(3)

# url 읽기
browser.get(url)

# 화면 캡쳐 및 저장
browser.save_screenshot('myshot.png')

# 브라우저 종료
browser.quit()
```

--------------------------------------------------------------------------------------------------------------------------------------------------------

```python
import requests
from bs4 import BeautifulSoup
import urllib.request as req

page=req.urlopen('http://www.rottentomatoes.com')
doc=page.read()
soup2=BeautifulSoup(doc, 'html.parser')
movies=soup2.find(id='homepage-top-box-office')
movie_list=movies.find_all('td', class_='middle_col')

#movie_list.get('a')
for movie in movie_list:
    print(movie.get_text())
    print('http://rottentomatoes.com'+movie.find('a').get('href'))
    

#Star Wars: The Rise of Skywalker
#http://rottentomatoes.com/m/star_wars_the_rise_of_skywalker
#Jumanji: The Next Level
#http://rottentomatoes.com/m/jumanji_the_next_level
#Little Women
#http://rottentomatoes.com/m/little_women_2019
#Frozen II
#http://rottentomatoes.com/m/frozen_ii
#Spies in Disguise
#http://rottentomatoes.com/m/spies_in_disguise
#Knives Out
#http://rottentomatoes.com/m/knives_out
#Uncut Gems
#http://rottentomatoes.com/m/uncut_gems
#Cats
#http://rottentomatoes.com/m/cats_2019
#Bombshell
#http://rottentomatoes.com/m/bombshell_2019
#Richard Jewell
#http://rottentomatoes.com/m/richard_jewell
```



```python
import requests 
from bs4 import BeautifulSoup
import urllib.request as req

url3='https://stackoverflow.com/questions/tagged/python'
response=requests.get(url3)
soup3=BeautifulSoup(response.text, 'html.parser')
links=[]
for link in soup3.select('div.question-summary h3 a'):       # 질문페이지 링크
    links.append(link.attrs['href'])
    #print('http://www.stackoverflow.com'+link.attrs['href'])
for link in links:
    url4='http://www.stackoverflow.com'+link                 # 답변 페이지
    response2=requests.get(url4)
    text=response.text
    soup4=BeautifulSoup(text, 'html.parser')
    print('question\n')
    for x in soup4.select('div.postcell div.post-text p'):
        print(x.text)
    print('\nanswer\n')
    for x in soup4.select('div.answercell div.post-text p'):
        print(x.text)
    print('='*40, '\n')
```


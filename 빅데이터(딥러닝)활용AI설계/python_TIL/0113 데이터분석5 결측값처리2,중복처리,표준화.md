### 결측값 처리 2



#### np.where(조건)                                 ->  index 형태로 출력

#### np.where(조건, 참, 거짓)  



```python
arr=np.array([1,2,3,10,20,30,0.1,0.2])

np.min(arr)

# min index 출력
np.argmin(arr)    

# max index 출력
np.argmax(arr)


np.where(arr<1)
#(array([6, 7], dtype=int64),)
np.where(arr>=10,0,arr)
#array([1. , 2. , 3. , 0. , 0. , 0. , 0.1, 0.2])
np.where(arr>=10,arr*0.1,arr)
#array([1. , 2. , 3. , 1. , 2. , 3. , 0.1, 0.2])
```



```python
import pandas as pd
import numpy as np

df=pd.DataFrame(np.random.randn(5,3), columns=['c1','c2','c3'])

## nan 지정하기
df.ix[0,0]=Nan
df.ix[1,['c1','c3']]=np.nan
df.ix[2,['c2']]=np.nan          

## nan 대신 다른 값 넣기
df.fillna(0)
df.fillna(method='ffill')

## nan 대신 평균값 넣기
df.fillna(df.mean()['c1'])
df.fillna(df.mean()['c1':'c2'])    # 특정 column에만 결측값 대체
df.where(pd.notnull(df),df.mean(),axis='columns')

---------------------------------------------------------------------

df2=pd.DataFrame({'c1':[1,2,3,4,5],
            'c2':[6,7,8,9,10]})

df2.ix[[1,3],['c2']]=np.nan

df2['c2p']=np.where(pd.notnull(df2['c2'])==True,df2['c2'],df2['c1'])
#=
for i in df2.index:
    if pd.notnull(df2.ix[i,'c2'])==True:
        df2.ix[i,'c2p']=df2.ix[i,'c2']
    else:
        df2.ix[i,'c2p']=df2.ix[i,'c1']    
```





#### ~.dropna(axis=0)       ->  결측값이 있는 row 전체 제거

#### ~.dropna(axis=1)       ->   결측값이 있는 column 전체 제거



```python
import pandas as pd
import numpy as np

df3=pd.DataFrame({'c1':[1,2,3,4,5],
            'c2':[6,7,8,9,10]})

df3.ix[[1,3],['c2']]=np.nan

df3.dropna(axis=0)
df3[['c1','c2']].dropna()

df3.dropna(axis=1)
df3[['c1','c2']].dropna(axis=1)




```



#### .interpolate() 결측값 보간

1 시계열data - 선형적으로 비례하는 값

2 이미지 data - 그라데이션



```python
import pandas as pd
import numpy as np

from datetime import datetime

dateStr=['1/13/2020','1/14/2020','1/15/2020','1/16/2020']
dates=pd.to_datetime(dateStr)

ts=pd.Series([1,np.nan,np.nan,10],index=dates)
2020-01-13     1.0
2020-01-16     NaN
2020-01-17     NaN
2020-01-20    10.0
dtype: float64

tslr=ts.interpolate(method='values')
2020-01-13     1.0
2020-01-16     4.0
2020-01-17     7.0
2020-01-20    10.0
dtype: float64
    
tsTime=ts.interpolate(method='time')
2020-01-13     1.000000
2020-01-16     4.857143
2020-01-17     6.142857
2020-01-20    10.000000
dtype: float64
    
tsTime=ts.interpolate(method='time',limit=1)
2020-01-13     1.000000
2020-01-16     4.857143
2020-01-17          NaN
2020-01-20    10.000000
dtype: float64
```







#### .replace()      ->  결측값&실측값 대상 데이터 데채



```python
import pandas as pd
import numpy as np

s=pd.Series([1,2,3,1,np.nan])

# (기존data,대체data)
s.replace(3,9)
0    1.0
1    2.0
2    9.0
3    1.0
4    NaN
dtype: float64
    
s.replace(np.nan,5)
0    1.0
1    2.0
2    3.0
3    1.0
4    5.0
dtype: float64
    
s.replace([1,2,3],[6,7,8])
0    6.0
1    7.0
2    8.0
3    6.0
4    NaN
dtype: float64
    
s.replace([1,2,3,np.nan],[10,20,30,99])
0    10.0
1    20.0
2    30.0
3    10.0
4    99.0
dtype: float64
    

# {기존data:대체data}    
s.replace({1:5})   
0    5.0
1    2.0
2    3.0
3    5.0
4    NaN
dtype: float64
    
-------------------------------------------------

df=pd.DataFrame({'c1':['aaa','b','c','d'],
                'c2':[1,2,3,4],
                'c3':[5,6,7,np.nan]})

df.replace({'c1':'aaa'},{'c1':'bbb'})
df.replace({'c3':np.nan},{'c3':99})
```





#### 중복 data 처리



#### .duplicated()      -> 중복 여부 확인

```python
import pandas as pd
import numpy as np

df=pd.DataFrame({'k1':['a','b','b','c','c'],
             'k2':['x','y','y','x','z'],
             'col':[10,20,30,40,50]})

## default : 위->아래
df.duplicated(['k1'])
df.duplicated(['k1'],keep='first')
0    False
1    False
2     True
3    False
4     True
dtype: bool
    
df.duplicated(['k2'])
0    False
1    False
2     True
3     True
4    False
dtype: bool
    
df.duplicated(['k1','k2'])    
0    False
1    False
2     True
3    False
4    False
dtype: bool
    

## 아래->위
df.duplicated(['k1'],keep='last')  
0    False
1     True
2    False
3     True
4    False
dtype: bool

    
## 중복data 모두 True
df.duplicated(['k1'],keep=False)
0    False
1     True
2     True
3     True
4     True
dtype: bool
    

```



####  .drop_duplicates()->  한 개만 남겨놓고 나머지 중복 제거



```python
import pandas as pd
import numpy as np

df=pd.DataFrame({'k1':['a','b','b','c','c'],
             'k2':['x','y','y','x','z'],
             'col':[10,20,30,40,50]})

df.drop_duplicates(['k1'])
df.drop_duplicates(['k1'],keep='first')

df.drop_duplicates(['k1'],keep='last')

df.drop_duplicates(['k1'],keep=False)
```



------------------------------------------------------------------------------------



#### .unique()      -> 유일한 값 찾기

#### .value_counts()      ->  유일한 값의 개수 



```python
import pandas as pd
import numpy as np

df=pd.DataFrame({'a':['a1','a1','a2','a2','a3'],
                'b':['b1','b1','b2','b2',np.nan],
                'c':[1,1,3,4,4]})

df['a'].unique()
#array(['a1', 'a2', 'a3'], dtype=object)

df['b'].unique()
#array(['b1', 'b2', nan], dtype=object)

--------------------------------------------------

## default : normalize=False    -> 유일한 값 개수
df['a'].value_counts()
df['a'].value_counts(normalize=False)
a2    2
a1    2
a3    1
Name: a, dtype: int64

## normalize=True   ->  유일한 값 상대비율
df['a'].value_counts(normalize=True)
a2    0.4
a1    0.4
a3    0.2
Name: a, dtype: float64
        
## default : sort=True, ascending=False    ->  유일한 값의 개수 기준으로 내림차순 정렬
df['a'].value_counts(sort=True,ascending=True)       
a3    1
a1    2
a2    2
Name: a, dtype: int64
        
df['a'].value_counts(sort=True,ascending=False) 
a2    2
a1    2
a3    1
Name: a, dtype: int64
        
df['c'].value_counts(sort=True, ascending=False)
4    2
1    2
3    1
Name: c, dtype: int64

df['c'].value_counts(sort=True, ascending=True)
3    1
1    2
4    2
Name: c, dtype: int64
        
## sort=False    ->  정렬 기준 없음
df['c'].value_counts(sort=False)
1    2
3    1
4    2
Name: c, dtype: int64
        
## default : dropna=True        
df['b'].value_counts()
df['b'].value_counts(dropna=True)
b2    2
b1    2
Name: b, dtype: int64

df['b'].value_counts(dropna=False)
b2     2
b1     2
NaN    1
Name: b, dtype: int64
        
## bins=[기간]   ->  구간별 data 개수
df['c'].value_counts(bins=[0,1,2,3,4,5],sort=False)
(-0.001, 1.0]    2
(1.0, 2.0]       0
(2.0, 3.0]       1
(3.0, 4.0]       2
(4.0, 5.0]       0
Name: c, dtype: int64

pd.cut(df['c'],bins=[0,1,2,3,4,5])
0    (0, 1]
1    (0, 1]
2    (2, 3]
3    (3, 4]
4    (3, 4]
Name: c, dtype: category
Categories (5, interval[int64]): [(0, 1] < (1, 2] < (2, 3] < (3, 4] < (4, 5]]
                                                                       
res=pd.cut(df['c'],bins=[0,1,2,3,4,5])
pd.value_counts(res)     
(3, 4]    2
(0, 1]    2
(2, 3]    1
(4, 5]    0
(1, 2]    0
Name: c, dtype: int64
 
 
## index 기준 정렬
s2.value_counts().sort_index()
 
## data 기준 / 특정 column 기준 정렬
s.sort_values() / df.sort_values(by=2) / df.sort_values(by=[1,2])
 
```





### data 표준화 

모집단이 정규본포를 따를 때, 평균=0, 표준편차=1 인 표준정규분포로 표준화 & 이상치(특이값) 존재 x

##### (각 data - 평균) / 표준편차

* numpy

* scipy.stats 

* scikit-learn.preprocessing



##### 1) numpy 표준화

```python
import pandas as pd
import numpy as np
from numpy import *

data=np.random.randint(5, size=(3,2))
#array([[3, 3],
#       [0, 3],
#       [2, 4]])

## 1) 분자
np.mean(data,axis=0)
#array([1.66666667, 3.33333333])

data-np.mean(data,axis=0)
#array([[ 1.33333333, -0.33333333],
#       [-1.66666667, -0.33333333],
#       [ 0.33333333,  0.66666667]])


## 2) 분모
np.std(data, axis=0)
#array([1.24721913, 0.47140452])


## 3) 표준화
std_data=data-np.mean(data,axis=0)/np.std(data, axis=0)
#array([[ 1.66369379, -4.07106781],
#       [-1.33630621, -4.07106781],
#       [ 0.66369379, -3.07106781]])


np.mean(std_data, axis=0)
np.std(std_data,axis=0)
np.var(std_data,axis=0)
```



##### 2) scify 표준화

```python
import pandas as pd
import numpy as np
from numpy import *

import scipy.stats as ss

data=np.random.randint(5, size=(3,2))

ss.zscore(data)
#array([[ 0.39223227, -1.41421356],
#       [-1.37281295,  0.70710678],
#       [ 0.98058068,  0.70710678]])
```



##### 3) scikit-learn 표준화

```python
import pandas as pd
import numpy as np
from numpy import *

from sklearn.preprocessing import *

data=np.random.randint(5, size=(3,2))

StandardScaler().fit_transform(data)
#array([[ 0.70710678,  0.70710678],
#      [ 0.70710678, -1.41421356],
#       [-1.41421356,  0.70710678]])

```



##### cf) RobustScaler()      ->   이상치(특이값)을 포함하는 data 표준화

> > 특이값 제거

```python
import pandas as pd
import numpy as np
from numpy import *

from sklearn.preprocessing import *
import matplotlib.pyplot as plt

mu, sigma=5,2

x=mu+sigma*np.random.randn(100)

plt.hist(x)
np.mean(x)   #4.951648692838198
np.std(x)    #1.9325179611598573

-----------------------------------------------
## 특이값 추가
x[98:100]=100

plt.hist(x)
np.mean(x)    #6.835124775876668
np.std(x)     #13.44797825307753

## 1차원 -> 2차원
x=x.reshape(-1,1)
ss_x=StandardScaler().fit_transform(x)

np.mean(ss_x)    
np.std(ss_x)
plt.hist(ss_x)

------------------------------------------------
## 특이값 제거
ss_x_z=ss_x[ss_x<5]
plt.hist(ss_x_z)

np.mean(ss_x_z)    
np.std(ss_x_z)
plt.hist(ss_x_z)
```



> > 중앙값(median), IQR 이용    ->  RobustScaler()    

```python
import pandas as pd
import numpy as np
from numpy import *

from sklearn.preprocessing import *
import matplotlib.pyplot as plt

mu, sigma=5,2

x=mu+sigma*np.random.randn(100)

np.median(x)

## 1사분위수
q1=np.percentile(x,25)  #3.6634400255919366

## 3사분위수
q3=np.percentile(x,75)   #6.198988668614078

## IQR
iqr=q3-q1   #2.5355486430221412

x_rs=RobustScaler().fit_transform(x)
np.median(x_rs)
np.mean(x_rs)
np.std(x_rs)
plt.hist(x_rs)
```


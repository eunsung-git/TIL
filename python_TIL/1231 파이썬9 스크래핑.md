### 데이터 수집

- db에서 수집 (정형데이터)

- 텍스트 수집 (비정형데이터)

### 파이썬 웹 데이터 추출

- **urllib** 라이브러리 (모듈집합)

- **request 모듈(urllib,request)**로 웹에 있는 데이터에 접근 가능

- **urlretrieve** 함수 이용



--------------------------------------------------------

#### urllib.request.urlretrieve()    -> 파일로 저장

```python
import urllib.request

url='https://www.multicampus.com/img/saas/main/logo/CUS0001/pc_main.png'
savename='test.png'

urllib.request.urlretrieve(url, savename)
print('저장')
```



#### urllib.request.urlopen()     -> 메모리에 적재, 파일로 저장 x

```python
import urllib.request

url='https://www.multicampus.com/img/saas/main/logo/CUS0001/pc_main.png'
savename='test2.png'
mem=urllib.request.urlopen(url).read()

with open(savename, mode='wb') as f:
    f.write(mem)
    print('저장')
```



#### urllib.parse.urlencode()    -> dict 형태를 stnId 형태로 바꿔줌

```python
import urllib.parse
import urllib.request

addr='http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp'
values={'stnId':'156'}
param=urllib.parse.urlencode(values)  

url=addr+'?'+param   
# 'http://www.weather.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=156'

data=urllib.request.urlopen(url).read()
text=data.decode('utf-8')
print(text)
```

--------------------



### 데이터 수집 과정
##### 1)  수집 대상 웹사이트에서 개발자 도구를 활용하여 스크랩 대상 선택자 복사
##### 2)  파이썬에서 urlretrieve/urlopen 등을 사용하여 웹페이지 불러오기
##### 3)  parsing - 수집한 웹문서에서 태그를 기준으로 원하는 데이터 추출

```python
import urllib.request as req
from bs4 import BeautifulSoup

url="https://finance.naver.com/marketindex/exchangeDetail.nhn?marketindexCd=FX_USDKRW" 
res=req.urlopen(url)
soup=BeautifulSoup(res, 'html.parser')

p=soup.select_one("#content > div.section_calculator > table:nth-child(4) > tbody > tr > td:nth-child(1)").text    
print(p)

# 1,156.50
```


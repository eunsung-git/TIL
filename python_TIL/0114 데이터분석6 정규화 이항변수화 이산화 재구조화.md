### data 정규화

0~1 사이의 범위로 data를 표준화

##### 0 < (각 data-min) / (max-min) < 1

```python
import numpy as np
import pandas as pd

from sklearn.preprocessing import MinMaxScaler

data=np.array([[10,-10,2],
              [5,0,6],
              [0,7,4]])

data.max(axis=0)-data.min(axis=0)  #array([10, 17,  4])

data-data.min(axis=0)  
#array([[10,  0,  0],
#       [ 5, 10,  4],
#       [ 0, 17,  2]])

data_mm=(data-data.min(axis=0))/data.max(axis=0)-data.min(axis=0)
#array([[ 1.        , 10.        , -2.        ],
#       [ 0.5       , 11.42857143, -1.33333333],
#       [ 0.        , 12.42857143, -1.66666667]])

-----------------------------------------------------------------

mms=MinMaxScaler()
mms.fit_transform(data)
#array([[1.        , 0.        , 0.        ],
#       [0.5       , 0.58823529, 1.        ],
#       [0.        , 1.        , 0.5       ]])

-----------------------------------------------------------------

from sklearn.preprocessing import minmax_scale
minmax_scale(data,axis=0)
#array([[1.        , 0.        , 0.        ],
#       [0.5       , 0.58823529, 1.        ],
#       [0.        , 1.        , 0.5       ]])
```



### 이항변수화

#### 1 binarize

확률변수 x가 이항분포를 따를 때, 연속형 변수를 기준에 따라 0 또는 1로 변환



```python
import numpy as np
import pandas as pd

from sklearn.preprocessing import Binarizer 

data=np.array([[10,-10,2],
              [5,0,6],
              [0,7,4]])

bina=Binarizer().fit(data)
bina=Binarizer(threshold=0).fit(data)
#Binarizer(copy=True, threshold=0.0)

bina.transform(data)
#array([[1, 0, 1],       0 이하 -> 0 / 0 초과 -> 1
#       [1, 0, 1],
#       [0, 1, 1]])


bina5=Binarizer(threshold=5).fit(data)
bina5.transform(data)
#array([[1, 0, 0],       5 이하 -> 0 / 5 초과 -> 1
#       [0, 0, 1],
#       [0, 1, 0]])

-------------------------------------------------------

from sklearn.preprocessing import binarize

data=np.array([[10,-10,2],
              [5,0,6],
              [0,7,4]])

binarize(data,threshold=5, copy=True)
#array([[1, 0, 0],
#       [0, 0, 1],
#       [0, 1, 0]])


```





#### 2 원핫인코더

확률변수 x가 이항분포를 따를 때, 범주형 변수를 기준에 따라 0 또는 1로 변환

```python
import numpy as np
import pandas as pd

from sklearn.preprocessing import OneHotEncoder 

data=np.array([[0,0,0],
              [0,1,1],
              [0,2,2],
              [1,0,3],
              [1,1,4]])

ohe=OneHotEncoder()

ohe.fit(data)

ohe.active_features_
#array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)

ohe.n_values_
#array([2, 3, 5])       범주의 개수

ohe.feature_indices_
#array([ 0,  2,  5, 10], dtype=int32)      범주의 범위

---------------------------------------------------------

data2=np.array([[1,2,3]])

ohe.transform(data2).toarray()
#array([[0., 1., 0., 0., 1., 0., 0., 0., 1., 0.]])
```





### 이산화

* 연속형 변수를 2개 이상의 범주를 갖는 변수로 변환

* 구간별 요약통계, 범주간 평균 차이, 독립성 검정, indexing 등에 활용

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({'C1': np.random.randn(20),
                   'C2': ['a', 'a', 'a', 'a', 'a', 
                          'a','a','a','a','a','b', 
                          'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']})

bins=np.linspace(df.C1.min(),df.C1.max(),10)    # 10개 구간으로 분할
#array([-1.91328024, -1.52522546, -1.13717068, -0.74911589, -0.36106111,
#        0.02699368,  0.41504846,  0.80310325,  1.19115803,  1.57921282])

df['C1_bin']=np.digitize(df.C1,bins)


## 그룹별 data 건수 
df.groupby('C1_bin')['C1'].size()

## 그룹별 data 평균
df.groupby('C1_bin')['C1'].mean()

## 그룹별 data 표준편차
df.groupby('C1_bin')['C1'].std()


df.groupby('C1_bin')['C2'].value_counts()


df[df["C1_bin"]==4]

-------------------------------------------------------------------------

pd.get_dummies(df['C1_bin'],prefix='C1')


```



```python
import numpy as np
import pandas as pd

df = pd.DataFrame({'C1': np.random.randn(20),
                   'C2': ['a', 'a', 'a', 'a', 'a', 
                          'a','a','a','a','a','b', 
                          'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']})

bins=np.linspace(df.C1.min(),df.C1.max(),10)    # 10개 구간으로 분할
#array([-1.91328024, -1.52522546, -1.13717068, -0.74911589, -0.36106111,
#        0.02699368,  0.41504846,  0.80310325,  1.19115803,  1.57921282])

df['C1_bin']=np.digitize(df.C1,bins)

df['h_l']=np.where(df['C1']>df.C1.mean(),'high','low')

df.groupby('h_l')['C1'].size()
df.groupby('h_l')['C1'].mean()
df.groupby('h_l')['C1'].std()


q1=np.percentile(df['C1'],25)
q3=np.percentile(df['C1'],75)


df['h_m_l']=np.where(df['C1']<=q1,'l','h')
df['h_m_l']=np.where(q1<df['C1'] & df['C1']<=q3,'m','h')

df['h_m_l']=np.where(df['C1']>=q3,'h',np.where(df['C1']>=q1,'m','l'))

```







### data 변형(재구조화)

#### pivot_table(data, index=,columns=,values=,aggfunc=)

```python
import numpy as np
import pandas as pd

data = pd.DataFrame({'cust_id': ['c1', 'c1', 'c1','c2','c2','c2','c3', 						'c3', 'c3'],'prod_cd': ['p1', 'p2', 'p3', 'p1', 					'p2', 'p3', 'p1', 'p2', 'p3'],'grade' : ['A', 'A', 						'A', 'A', 'A', 'A', 'B', 'B', 'B'],'pch_amt': 						[30, 10, 0, 40, 15, 30, 0, 0, 10]})

data.pivot(index='cust_id',columns='prod_cd',values='pch_amt')

pd.pivot_table(data,index='cust_id',columns='prod_cd',values='pch_amt')

pd.pivot_table(data,index=['cust_id','grade'],columns='prod_cd',values='pch_amt')

pd.pivot_table(data,index='cust_id',columns=['grade','prod_cd'],values='pch_amt')

---------------------------------------------------------------

## 평균
pd.pivot_table(data, index='grade',columns='prod_cd',values='pch_amt')
pd.pivot_table(data, index='grade',columns='prod_cd',values='pch_amt',aggfunc=np.mean)

pd.pivot_table(data, index='grade',columns='prod_cd',values='pch_amt',aggfunc=np.sum)
```



#### stack() / unstack()



```python
import numpy as np
import pandas as pd

mul_index = pd.MultiIndex.from_tuples([('cust_1', '2020'), ('cust_1', 											'2021'),('cust_2', '2020'), 											('cust_2', '2021')])  

data = pd.DataFrame(data=np.arange(16).reshape(4, 4),
					index=mul_index,columns=['prd_1', 'prd_2', 'prd_3', 					'prd_4'],dtype='int')

data_std=data.stack()

data_std.index

data_std['cust_2']['2020'][['prd_1','prd_2']]
#prd_1    8
#prd_2    9
#dtype: int32


data.ix[['cust_2'],['prd_4']]=None
data.ix['cust_2','prd_4']=None


## nan까지 모두 stack
data_std=data.stack(dropna=False)
```







#### melt()

```python
import numpy as np
import pandas as pd

data = pd.DataFrame({'cust_ID' : ['C_001', 'C_001', 'C_002', 'C_002'],
					'prd_CD' : ['P_001', 'P_002', 'P_001', 'P_002'],
					'pch_cnt' : [1, 2, 3, 4],
					'pch_amt' : [100, 200, 300, 400]})


## 고정하고자 하는 column 지정
pd.melt(data,id_vars=['cust_ID','prd_CD'])
pd.melt(data,id_vars=['cust_ID','prd_CD'],var_name='CD',value_name='VAL')

```





```python
import numpy as np
import pandas as pd

s=pd.Series(range(10))
s[3]=np.nan

df=pd.DataFrame(np.random.randint(5,size=(4,4)),dtype=float)
```



-----------------------------------------------------------------------------------------------

#### cut()  / qcut()

실수값의 경계 지정  / 구간 나누기

```python
import numpy as np
import pandas as pd

ages=[0,2,10,21,23,37,31,61,20,42,32,100]
labels=['미성년자','청년','중년','장년','노년']
bins=[1,15,25,35,60,99]

cats=pd.cut(ages, bins, labels=labels)
#[NaN, 미성년자, 미성년자, 청년, 청년, ..., 노년, 청년, 장년, 중년, NaN]
#Length: 12
#Categories (5, object): [미성년자 < 청년 < 중년 < 장년 < 노년]

cats.codes
#array([-1,  0,  0,  1,  1,  3,  2,  4,  1,  3,  2, -1], dtype=int8)


df=pd.DataFrame(ages,columns=['ages'])

df['age_cat']=pd.cut(ages, bins, labels=labels)

---------------------------------------------------------------------

data=np.random.randn(100)

pd.qcut(data,4,labels=['q1','q2','q3','q4'])
#[q4, q1, q1, q4, q3, ..., q1, q2, q2, q1, q2]
#Length: 100
#Categories (4, object): [q1 < q2 < q3 < q4]


```


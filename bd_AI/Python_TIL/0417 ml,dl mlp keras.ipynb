{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### keras model 만들기\n",
    "## 1) 데이터셋 생성\n",
    "(xtrain,ytrain),(xtest,ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape(60000,784).astype('float32')/255.0\n",
    "xtest = xtest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫인코딩\n",
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytest = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) model 구성\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3) 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.6608 - accuracy: 0.8319\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.3452 - accuracy: 0.9023\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.2983 - accuracy: 0.9155\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2694 - accuracy: 0.9239\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2470 - accuracy: 0.9304\n"
     ]
    }
   ],
   "source": [
    "## 4) model 학습\n",
    "hist = model.fit(xtrain,ytrain,epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.660846442190806, 0.3452354679663976, 0.29834899283448857, 0.26937211222449936, 0.24702843420406181]\n",
      "[0.8319167, 0.9023, 0.9155, 0.92391664, 0.93043333]\n"
     ]
    }
   ],
   "source": [
    "## 5) cost, accuracy 측정\n",
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "## 6) model 평가\n",
    "res = model.evaluate(xtest,ytest, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4842747e-04, 9.0432344e-08, 8.8094396e-04, 9.0934383e-03,\n",
       "        7.3074608e-07, 8.2192841e-05, 1.3494588e-08, 9.8891371e-01,\n",
       "        3.9105482e-05, 8.4119523e-04]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat = xtest[0:1]\n",
    "yhat = model.predict(xhat)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain,ytrain),(xtest,ytest) = mnist.load_data()\n",
    "\n",
    "xval = xtrain[50000:]\n",
    "yval = ytrain[50000:]\n",
    "\n",
    "xtrain = xtrain[:50000]\n",
    "ytrain = ytrain[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape(50000,784).astype('float32')/255.0\n",
    "xval = xval.reshape(10000,784).astype('float32')/255.0\n",
    "xtest = xtest.reshape(10000,784).astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = np.random.choice(50000,700)\n",
    "vri = np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain[tri]\n",
    "ytrain = ytrain[tri]\n",
    "xval = xval[vri]\n",
    "yval = yval[vri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "yval = np_utils.to_categorical(yval)\n",
    "ytest = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim=28*28, units=2, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 229us/step - loss: 2.3128 - accuracy: 0.0886 - val_loss: 2.3054 - val_accuracy: 0.0933\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 2.2974 - accuracy: 0.1371 - val_loss: 2.2900 - val_accuracy: 0.1500\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 2.2486 - accuracy: 0.1686 - val_loss: 2.2056 - val_accuracy: 0.2067\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 2.1713 - accuracy: 0.2300 - val_loss: 2.1372 - val_accuracy: 0.2267\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 2.1005 - accuracy: 0.2586 - val_loss: 2.0720 - val_accuracy: 0.2600\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 2.0417 - accuracy: 0.2629 - val_loss: 2.0191 - val_accuracy: 0.2933\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.9931 - accuracy: 0.2829 - val_loss: 1.9763 - val_accuracy: 0.2967\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.9490 - accuracy: 0.2800 - val_loss: 1.9411 - val_accuracy: 0.3500\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.9125 - accuracy: 0.3200 - val_loss: 1.9118 - val_accuracy: 0.3533\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.8780 - accuracy: 0.3314 - val_loss: 1.8889 - val_accuracy: 0.3633\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.8505 - accuracy: 0.3371 - val_loss: 1.8640 - val_accuracy: 0.3367\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.8210 - accuracy: 0.3471 - val_loss: 1.8431 - val_accuracy: 0.3367\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.7959 - accuracy: 0.3629 - val_loss: 1.8275 - val_accuracy: 0.3467\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.7724 - accuracy: 0.3629 - val_loss: 1.8117 - val_accuracy: 0.3567\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7500 - accuracy: 0.3657 - val_loss: 1.8000 - val_accuracy: 0.3533\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.7296 - accuracy: 0.3714 - val_loss: 1.7837 - val_accuracy: 0.3567\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.7117 - accuracy: 0.3714 - val_loss: 1.7716 - val_accuracy: 0.3567\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6924 - accuracy: 0.3757 - val_loss: 1.7670 - val_accuracy: 0.3467\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6773 - accuracy: 0.3757 - val_loss: 1.7503 - val_accuracy: 0.3600\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6597 - accuracy: 0.3729 - val_loss: 1.7396 - val_accuracy: 0.3667\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6456 - accuracy: 0.3771 - val_loss: 1.7329 - val_accuracy: 0.3567\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.6302 - accuracy: 0.3814 - val_loss: 1.7198 - val_accuracy: 0.3633\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.6164 - accuracy: 0.3743 - val_loss: 1.7182 - val_accuracy: 0.3667\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.6046 - accuracy: 0.3886 - val_loss: 1.7073 - val_accuracy: 0.3767\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.5918 - accuracy: 0.4000 - val_loss: 1.6951 - val_accuracy: 0.3833\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5803 - accuracy: 0.4057 - val_loss: 1.6863 - val_accuracy: 0.3900\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5678 - accuracy: 0.4029 - val_loss: 1.6922 - val_accuracy: 0.3933\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.5562 - accuracy: 0.4200 - val_loss: 1.6770 - val_accuracy: 0.3967\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5447 - accuracy: 0.4200 - val_loss: 1.6726 - val_accuracy: 0.3967\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5334 - accuracy: 0.4286 - val_loss: 1.6613 - val_accuracy: 0.4067\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.5224 - accuracy: 0.4343 - val_loss: 1.6566 - val_accuracy: 0.4067\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5108 - accuracy: 0.4457 - val_loss: 1.6528 - val_accuracy: 0.4133\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5024 - accuracy: 0.4443 - val_loss: 1.6376 - val_accuracy: 0.4167\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4915 - accuracy: 0.4514 - val_loss: 1.6361 - val_accuracy: 0.4333\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4807 - accuracy: 0.4529 - val_loss: 1.6294 - val_accuracy: 0.4267\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4715 - accuracy: 0.4543 - val_loss: 1.6234 - val_accuracy: 0.4233\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4628 - accuracy: 0.4657 - val_loss: 1.6200 - val_accuracy: 0.4300\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4530 - accuracy: 0.4657 - val_loss: 1.6230 - val_accuracy: 0.4333\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4443 - accuracy: 0.4614 - val_loss: 1.6145 - val_accuracy: 0.4333\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4343 - accuracy: 0.4686 - val_loss: 1.6017 - val_accuracy: 0.4267\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4263 - accuracy: 0.4729 - val_loss: 1.6048 - val_accuracy: 0.4333\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4192 - accuracy: 0.4771 - val_loss: 1.5977 - val_accuracy: 0.4367\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4109 - accuracy: 0.4729 - val_loss: 1.5881 - val_accuracy: 0.4333\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4032 - accuracy: 0.4886 - val_loss: 1.5877 - val_accuracy: 0.4400\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3951 - accuracy: 0.4814 - val_loss: 1.5865 - val_accuracy: 0.4467\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.3891 - accuracy: 0.4829 - val_loss: 1.5781 - val_accuracy: 0.4300\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3816 - accuracy: 0.4929 - val_loss: 1.5752 - val_accuracy: 0.4300\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3750 - accuracy: 0.4957 - val_loss: 1.5746 - val_accuracy: 0.4433\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.3678 - accuracy: 0.4914 - val_loss: 1.5736 - val_accuracy: 0.4433\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3614 - accuracy: 0.5014 - val_loss: 1.5666 - val_accuracy: 0.4300\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3558 - accuracy: 0.4943 - val_loss: 1.5640 - val_accuracy: 0.4400\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.3484 - accuracy: 0.4943 - val_loss: 1.5658 - val_accuracy: 0.4433\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.3423 - accuracy: 0.5043 - val_loss: 1.5595 - val_accuracy: 0.4333\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3378 - accuracy: 0.5043 - val_loss: 1.5664 - val_accuracy: 0.4400\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3333 - accuracy: 0.5029 - val_loss: 1.5588 - val_accuracy: 0.4433\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.3270 - accuracy: 0.4971 - val_loss: 1.5497 - val_accuracy: 0.4367\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.3208 - accuracy: 0.5057 - val_loss: 1.5472 - val_accuracy: 0.4333\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.3167 - accuracy: 0.5086 - val_loss: 1.5531 - val_accuracy: 0.4433\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.3115 - accuracy: 0.4957 - val_loss: 1.5485 - val_accuracy: 0.4433\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.3069 - accuracy: 0.5071 - val_loss: 1.5481 - val_accuracy: 0.4500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3018 - accuracy: 0.5100 - val_loss: 1.5474 - val_accuracy: 0.4333\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.2983 - accuracy: 0.5129 - val_loss: 1.5462 - val_accuracy: 0.4400\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2926 - accuracy: 0.5086 - val_loss: 1.5413 - val_accuracy: 0.4433\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.2888 - accuracy: 0.5171 - val_loss: 1.5433 - val_accuracy: 0.4400\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2834 - accuracy: 0.5171 - val_loss: 1.5363 - val_accuracy: 0.4500\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2793 - accuracy: 0.5186 - val_loss: 1.5416 - val_accuracy: 0.4533\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2757 - accuracy: 0.5286 - val_loss: 1.5433 - val_accuracy: 0.4500\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2705 - accuracy: 0.5214 - val_loss: 1.5342 - val_accuracy: 0.4267\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.2678 - accuracy: 0.5229 - val_loss: 1.5380 - val_accuracy: 0.4333\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2624 - accuracy: 0.5257 - val_loss: 1.5342 - val_accuracy: 0.4400\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2584 - accuracy: 0.5271 - val_loss: 1.5329 - val_accuracy: 0.4367\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2549 - accuracy: 0.5200 - val_loss: 1.5323 - val_accuracy: 0.4433\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2525 - accuracy: 0.5257 - val_loss: 1.5401 - val_accuracy: 0.4500\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.2461 - accuracy: 0.5257 - val_loss: 1.5363 - val_accuracy: 0.4467\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.2439 - accuracy: 0.5271 - val_loss: 1.5365 - val_accuracy: 0.4400\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2371 - accuracy: 0.5357 - val_loss: 1.5438 - val_accuracy: 0.4433\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.2377 - accuracy: 0.5371 - val_loss: 1.5334 - val_accuracy: 0.4433\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2318 - accuracy: 0.5371 - val_loss: 1.5344 - val_accuracy: 0.4433\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2294 - accuracy: 0.5357 - val_loss: 1.5439 - val_accuracy: 0.4533\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2260 - accuracy: 0.5286 - val_loss: 1.5371 - val_accuracy: 0.4500\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2220 - accuracy: 0.5371 - val_loss: 1.5463 - val_accuracy: 0.4600\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2203 - accuracy: 0.5443 - val_loss: 1.5409 - val_accuracy: 0.4433\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.2166 - accuracy: 0.5443 - val_loss: 1.5420 - val_accuracy: 0.4567\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2128 - accuracy: 0.5400 - val_loss: 1.5450 - val_accuracy: 0.4567\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.2096 - accuracy: 0.5400 - val_loss: 1.5383 - val_accuracy: 0.4467\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.2063 - accuracy: 0.5457 - val_loss: 1.5469 - val_accuracy: 0.4600\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.2042 - accuracy: 0.5500 - val_loss: 1.5368 - val_accuracy: 0.4500\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.2006 - accuracy: 0.5457 - val_loss: 1.5411 - val_accuracy: 0.4600\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1969 - accuracy: 0.5357 - val_loss: 1.5335 - val_accuracy: 0.4433\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1936 - accuracy: 0.5486 - val_loss: 1.5467 - val_accuracy: 0.4567\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.1918 - accuracy: 0.5400 - val_loss: 1.5419 - val_accuracy: 0.4433\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1887 - accuracy: 0.5400 - val_loss: 1.5504 - val_accuracy: 0.4600\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1861 - accuracy: 0.5500 - val_loss: 1.5431 - val_accuracy: 0.4633\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1836 - accuracy: 0.5443 - val_loss: 1.5530 - val_accuracy: 0.4567\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.1801 - accuracy: 0.5529 - val_loss: 1.5362 - val_accuracy: 0.4500\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1758 - accuracy: 0.5429 - val_loss: 1.5470 - val_accuracy: 0.4600\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1736 - accuracy: 0.5571 - val_loss: 1.5469 - val_accuracy: 0.4567\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1716 - accuracy: 0.5443 - val_loss: 1.5406 - val_accuracy: 0.4567\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1678 - accuracy: 0.5529 - val_loss: 1.5471 - val_accuracy: 0.4567\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1664 - accuracy: 0.5557 - val_loss: 1.5509 - val_accuracy: 0.4667\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.1630 - accuracy: 0.5471 - val_loss: 1.5492 - val_accuracy: 0.4633\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1610 - accuracy: 0.5500 - val_loss: 1.5484 - val_accuracy: 0.4633\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.1576 - accuracy: 0.5543 - val_loss: 1.5502 - val_accuracy: 0.4633\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.1550 - accuracy: 0.5614 - val_loss: 1.5499 - val_accuracy: 0.4633\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.1546 - accuracy: 0.5500 - val_loss: 1.5558 - val_accuracy: 0.4633\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1500 - accuracy: 0.5571 - val_loss: 1.5655 - val_accuracy: 0.4600\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1486 - accuracy: 0.5543 - val_loss: 1.5609 - val_accuracy: 0.4733\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1467 - accuracy: 0.5614 - val_loss: 1.5559 - val_accuracy: 0.4633\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.1436 - accuracy: 0.5571 - val_loss: 1.5515 - val_accuracy: 0.4633\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.1410 - accuracy: 0.5514 - val_loss: 1.5615 - val_accuracy: 0.4600\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.1376 - accuracy: 0.5686 - val_loss: 1.5584 - val_accuracy: 0.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1356 - accuracy: 0.5586 - val_loss: 1.5575 - val_accuracy: 0.4667\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1342 - accuracy: 0.5571 - val_loss: 1.5632 - val_accuracy: 0.4733\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1317 - accuracy: 0.5629 - val_loss: 1.5631 - val_accuracy: 0.4633\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.1290 - accuracy: 0.5571 - val_loss: 1.5676 - val_accuracy: 0.4633\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1284 - accuracy: 0.5614 - val_loss: 1.5632 - val_accuracy: 0.4667\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.1249 - accuracy: 0.5643 - val_loss: 1.5604 - val_accuracy: 0.4767\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1227 - accuracy: 0.5686 - val_loss: 1.5651 - val_accuracy: 0.4667\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1195 - accuracy: 0.5657 - val_loss: 1.5637 - val_accuracy: 0.4700\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1184 - accuracy: 0.5586 - val_loss: 1.5646 - val_accuracy: 0.4667\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.1160 - accuracy: 0.5700 - val_loss: 1.5614 - val_accuracy: 0.4700\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.1146 - accuracy: 0.5686 - val_loss: 1.5734 - val_accuracy: 0.4700\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.1123 - accuracy: 0.5686 - val_loss: 1.5688 - val_accuracy: 0.4633\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.1090 - accuracy: 0.5729 - val_loss: 1.5636 - val_accuracy: 0.4733\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.1088 - accuracy: 0.5686 - val_loss: 1.5731 - val_accuracy: 0.4633\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.1060 - accuracy: 0.5714 - val_loss: 1.5714 - val_accuracy: 0.4600\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.1037 - accuracy: 0.5657 - val_loss: 1.5736 - val_accuracy: 0.4633\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.1014 - accuracy: 0.5700 - val_loss: 1.5735 - val_accuracy: 0.4667\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0999 - accuracy: 0.5729 - val_loss: 1.5732 - val_accuracy: 0.4700\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0977 - accuracy: 0.5714 - val_loss: 1.5737 - val_accuracy: 0.4667\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0954 - accuracy: 0.5771 - val_loss: 1.5740 - val_accuracy: 0.4733\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0928 - accuracy: 0.5729 - val_loss: 1.5757 - val_accuracy: 0.4633\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.0903 - accuracy: 0.5800 - val_loss: 1.5724 - val_accuracy: 0.4667\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0906 - accuracy: 0.5629 - val_loss: 1.5818 - val_accuracy: 0.4667\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0871 - accuracy: 0.5771 - val_loss: 1.5735 - val_accuracy: 0.4600\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0866 - accuracy: 0.5786 - val_loss: 1.5872 - val_accuracy: 0.4700\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0839 - accuracy: 0.5700 - val_loss: 1.5856 - val_accuracy: 0.4633\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0830 - accuracy: 0.5800 - val_loss: 1.5839 - val_accuracy: 0.4567\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.0804 - accuracy: 0.5671 - val_loss: 1.5842 - val_accuracy: 0.4633\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0795 - accuracy: 0.5786 - val_loss: 1.5888 - val_accuracy: 0.4633\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.0769 - accuracy: 0.5800 - val_loss: 1.5820 - val_accuracy: 0.4700\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0763 - accuracy: 0.5743 - val_loss: 1.5911 - val_accuracy: 0.4600\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0753 - accuracy: 0.5771 - val_loss: 1.5904 - val_accuracy: 0.4600\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0711 - accuracy: 0.5771 - val_loss: 1.5847 - val_accuracy: 0.4767\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.0709 - accuracy: 0.5771 - val_loss: 1.5929 - val_accuracy: 0.4667\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.0691 - accuracy: 0.5843 - val_loss: 1.5893 - val_accuracy: 0.4700\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.0680 - accuracy: 0.5771 - val_loss: 1.5964 - val_accuracy: 0.4700\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0663 - accuracy: 0.5829 - val_loss: 1.6033 - val_accuracy: 0.4733\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0629 - accuracy: 0.5886 - val_loss: 1.5957 - val_accuracy: 0.4633\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.0611 - accuracy: 0.5829 - val_loss: 1.5927 - val_accuracy: 0.4700\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0606 - accuracy: 0.5857 - val_loss: 1.6037 - val_accuracy: 0.4667\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0592 - accuracy: 0.5829 - val_loss: 1.5985 - val_accuracy: 0.4800\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0572 - accuracy: 0.5743 - val_loss: 1.6007 - val_accuracy: 0.4600\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0547 - accuracy: 0.5900 - val_loss: 1.6011 - val_accuracy: 0.4667\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0530 - accuracy: 0.5857 - val_loss: 1.6050 - val_accuracy: 0.4633\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.0535 - accuracy: 0.5929 - val_loss: 1.6017 - val_accuracy: 0.4667\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.0510 - accuracy: 0.5900 - val_loss: 1.6137 - val_accuracy: 0.4633\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0503 - accuracy: 0.5886 - val_loss: 1.6040 - val_accuracy: 0.4700\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0478 - accuracy: 0.5957 - val_loss: 1.6138 - val_accuracy: 0.4733\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0466 - accuracy: 0.5929 - val_loss: 1.6069 - val_accuracy: 0.4633\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 1.0454 - accuracy: 0.5871 - val_loss: 1.6063 - val_accuracy: 0.4800\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0455 - accuracy: 0.5829 - val_loss: 1.6123 - val_accuracy: 0.4800\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0416 - accuracy: 0.5900 - val_loss: 1.6283 - val_accuracy: 0.4567\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.0422 - accuracy: 0.5914 - val_loss: 1.6065 - val_accuracy: 0.4733\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.0503 - accuracy: 0.59 - 0s 109us/step - loss: 1.0382 - accuracy: 0.5929 - val_loss: 1.6238 - val_accuracy: 0.4667\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.0393 - accuracy: 0.5929 - val_loss: 1.6184 - val_accuracy: 0.4767\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.0382 - accuracy: 0.5929 - val_loss: 1.6151 - val_accuracy: 0.4800\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.0346 - accuracy: 0.5914 - val_loss: 1.6118 - val_accuracy: 0.4767\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.0337 - accuracy: 0.5886 - val_loss: 1.6149 - val_accuracy: 0.4767\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.0325 - accuracy: 0.5986 - val_loss: 1.6111 - val_accuracy: 0.4733\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0313 - accuracy: 0.6000 - val_loss: 1.6215 - val_accuracy: 0.4833\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0299 - accuracy: 0.5957 - val_loss: 1.6172 - val_accuracy: 0.4767\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0289 - accuracy: 0.6071 - val_loss: 1.6235 - val_accuracy: 0.4767\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0277 - accuracy: 0.5886 - val_loss: 1.6275 - val_accuracy: 0.4733\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0276 - accuracy: 0.5943 - val_loss: 1.6227 - val_accuracy: 0.4733\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0243 - accuracy: 0.5986 - val_loss: 1.6416 - val_accuracy: 0.4567\n",
      "Epoch 177/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.0237 - accuracy: 0.5957 - val_loss: 1.6403 - val_accuracy: 0.4700\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.0216 - accuracy: 0.5986 - val_loss: 1.6321 - val_accuracy: 0.4633\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0190 - accuracy: 0.6000 - val_loss: 1.6485 - val_accuracy: 0.4633\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.0196 - accuracy: 0.5986 - val_loss: 1.6354 - val_accuracy: 0.4700\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0175 - accuracy: 0.6029 - val_loss: 1.6456 - val_accuracy: 0.4733\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.0170 - accuracy: 0.6000 - val_loss: 1.6394 - val_accuracy: 0.4733\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.0162 - accuracy: 0.6029 - val_loss: 1.6425 - val_accuracy: 0.4633\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.0141 - accuracy: 0.6000 - val_loss: 1.6467 - val_accuracy: 0.4733\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.0129 - accuracy: 0.5957 - val_loss: 1.6577 - val_accuracy: 0.4633\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.0105 - accuracy: 0.6029 - val_loss: 1.6418 - val_accuracy: 0.4733\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.0122 - accuracy: 0.6014 - val_loss: 1.6355 - val_accuracy: 0.4767\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.0092 - accuracy: 0.6114 - val_loss: 1.6444 - val_accuracy: 0.4767\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.0082 - accuracy: 0.6029 - val_loss: 1.6406 - val_accuracy: 0.4733\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.0059 - accuracy: 0.6000 - val_loss: 1.6383 - val_accuracy: 0.4633\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.0069 - accuracy: 0.6100 - val_loss: 1.6408 - val_accuracy: 0.4767\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.0043 - accuracy: 0.6043 - val_loss: 1.6445 - val_accuracy: 0.4767\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.0024 - accuracy: 0.6071 - val_loss: 1.6553 - val_accuracy: 0.4733\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.0028 - accuracy: 0.6086 - val_loss: 1.6467 - val_accuracy: 0.4800\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.0003 - accuracy: 0.6057 - val_loss: 1.6590 - val_accuracy: 0.4667\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9998 - accuracy: 0.6057 - val_loss: 1.6526 - val_accuracy: 0.4800\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9991 - accuracy: 0.6114 - val_loss: 1.6550 - val_accuracy: 0.4800\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9975 - accuracy: 0.6086 - val_loss: 1.6631 - val_accuracy: 0.4733\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9964 - accuracy: 0.6057 - val_loss: 1.6580 - val_accuracy: 0.4700\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9966 - accuracy: 0.6114 - val_loss: 1.6506 - val_accuracy: 0.4800\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9936 - accuracy: 0.6043 - val_loss: 1.6545 - val_accuracy: 0.4700\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9928 - accuracy: 0.6071 - val_loss: 1.6555 - val_accuracy: 0.4733\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9891 - accuracy: 0.6214 - val_loss: 1.6472 - val_accuracy: 0.4800\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9918 - accuracy: 0.6129 - val_loss: 1.6643 - val_accuracy: 0.4833\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9902 - accuracy: 0.6114 - val_loss: 1.6566 - val_accuracy: 0.4767\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9892 - accuracy: 0.6129 - val_loss: 1.6563 - val_accuracy: 0.4700\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.9882 - accuracy: 0.6157 - val_loss: 1.6675 - val_accuracy: 0.4767\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9860 - accuracy: 0.6157 - val_loss: 1.6607 - val_accuracy: 0.4733\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9855 - accuracy: 0.6186 - val_loss: 1.6632 - val_accuracy: 0.4767\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9832 - accuracy: 0.6243 - val_loss: 1.6654 - val_accuracy: 0.4767\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9825 - accuracy: 0.6229 - val_loss: 1.6674 - val_accuracy: 0.4767\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.9813 - accuracy: 0.6200 - val_loss: 1.6714 - val_accuracy: 0.4767\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9807 - accuracy: 0.6171 - val_loss: 1.6810 - val_accuracy: 0.4733\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9774 - accuracy: 0.6157 - val_loss: 1.6854 - val_accuracy: 0.4800\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9782 - accuracy: 0.6200 - val_loss: 1.6718 - val_accuracy: 0.4767\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9771 - accuracy: 0.6186 - val_loss: 1.6789 - val_accuracy: 0.4733\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9756 - accuracy: 0.6200 - val_loss: 1.6845 - val_accuracy: 0.4800\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9748 - accuracy: 0.6200 - val_loss: 1.6763 - val_accuracy: 0.4767\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9721 - accuracy: 0.6257 - val_loss: 1.6739 - val_accuracy: 0.4533\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9737 - accuracy: 0.6286 - val_loss: 1.6744 - val_accuracy: 0.4733\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9714 - accuracy: 0.6229 - val_loss: 1.6809 - val_accuracy: 0.4700\n",
      "Epoch 222/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 104us/step - loss: 0.9708 - accuracy: 0.6257 - val_loss: 1.6843 - val_accuracy: 0.4700\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9691 - accuracy: 0.6300 - val_loss: 1.6741 - val_accuracy: 0.4733\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9690 - accuracy: 0.6314 - val_loss: 1.6772 - val_accuracy: 0.4700\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9674 - accuracy: 0.6329 - val_loss: 1.6792 - val_accuracy: 0.4700\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9666 - accuracy: 0.6243 - val_loss: 1.6789 - val_accuracy: 0.4700\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9656 - accuracy: 0.6271 - val_loss: 1.6826 - val_accuracy: 0.4667\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.9645 - accuracy: 0.6286 - val_loss: 1.6887 - val_accuracy: 0.4633\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.9637 - accuracy: 0.6286 - val_loss: 1.6874 - val_accuracy: 0.4733\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9632 - accuracy: 0.6214 - val_loss: 1.6897 - val_accuracy: 0.4700\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.9618 - accuracy: 0.6300 - val_loss: 1.6831 - val_accuracy: 0.4700\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9616 - accuracy: 0.6300 - val_loss: 1.6918 - val_accuracy: 0.4767\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9613 - accuracy: 0.6414 - val_loss: 1.6877 - val_accuracy: 0.4667\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9596 - accuracy: 0.6386 - val_loss: 1.6962 - val_accuracy: 0.4700\n",
      "Epoch 235/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9580 - accuracy: 0.6343 - val_loss: 1.7013 - val_accuracy: 0.4667\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.9577 - accuracy: 0.6286 - val_loss: 1.7016 - val_accuracy: 0.4667\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.9563 - accuracy: 0.6343 - val_loss: 1.6931 - val_accuracy: 0.4667\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.9562 - accuracy: 0.6386 - val_loss: 1.7027 - val_accuracy: 0.4767\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9533 - accuracy: 0.6343 - val_loss: 1.6871 - val_accuracy: 0.4600\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9544 - accuracy: 0.6386 - val_loss: 1.6990 - val_accuracy: 0.4667\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.9530 - accuracy: 0.6386 - val_loss: 1.6903 - val_accuracy: 0.4733\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.9516 - accuracy: 0.6471 - val_loss: 1.7107 - val_accuracy: 0.4700\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.9518 - accuracy: 0.6386 - val_loss: 1.7109 - val_accuracy: 0.4667\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9499 - accuracy: 0.6314 - val_loss: 1.7154 - val_accuracy: 0.4700\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9491 - accuracy: 0.6386 - val_loss: 1.7021 - val_accuracy: 0.4667\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9470 - accuracy: 0.6343 - val_loss: 1.7165 - val_accuracy: 0.4733\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9475 - accuracy: 0.6400 - val_loss: 1.7182 - val_accuracy: 0.4633\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9472 - accuracy: 0.6414 - val_loss: 1.7115 - val_accuracy: 0.4633\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.9454 - accuracy: 0.6443 - val_loss: 1.6998 - val_accuracy: 0.4733\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9455 - accuracy: 0.6471 - val_loss: 1.7137 - val_accuracy: 0.4667\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9440 - accuracy: 0.6414 - val_loss: 1.7161 - val_accuracy: 0.4767\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9440 - accuracy: 0.6371 - val_loss: 1.7224 - val_accuracy: 0.4633\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9440 - accuracy: 0.6400 - val_loss: 1.7232 - val_accuracy: 0.4667\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9409 - accuracy: 0.6414 - val_loss: 1.7328 - val_accuracy: 0.4767\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9407 - accuracy: 0.6443 - val_loss: 1.7304 - val_accuracy: 0.4633\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9398 - accuracy: 0.6400 - val_loss: 1.7226 - val_accuracy: 0.4600\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9382 - accuracy: 0.6514 - val_loss: 1.7177 - val_accuracy: 0.4600\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9382 - accuracy: 0.6471 - val_loss: 1.7235 - val_accuracy: 0.4667\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9373 - accuracy: 0.6471 - val_loss: 1.7367 - val_accuracy: 0.4667\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.9365 - accuracy: 0.6457 - val_loss: 1.7316 - val_accuracy: 0.4667\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9362 - accuracy: 0.6471 - val_loss: 1.7316 - val_accuracy: 0.4700\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9352 - accuracy: 0.6500 - val_loss: 1.7206 - val_accuracy: 0.4700\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9329 - accuracy: 0.6457 - val_loss: 1.7425 - val_accuracy: 0.4500\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9333 - accuracy: 0.6486 - val_loss: 1.7328 - val_accuracy: 0.4633\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9322 - accuracy: 0.6457 - val_loss: 1.7402 - val_accuracy: 0.4567\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.9323 - accuracy: 0.6457 - val_loss: 1.7515 - val_accuracy: 0.4633\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.9317 - accuracy: 0.6429 - val_loss: 1.7420 - val_accuracy: 0.4600\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.9305 - accuracy: 0.6471 - val_loss: 1.7526 - val_accuracy: 0.4667\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.9290 - accuracy: 0.6500 - val_loss: 1.7513 - val_accuracy: 0.4533\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.9283 - accuracy: 0.6471 - val_loss: 1.7436 - val_accuracy: 0.4567\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9280 - accuracy: 0.6500 - val_loss: 1.7402 - val_accuracy: 0.4567\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9271 - accuracy: 0.6571 - val_loss: 1.7464 - val_accuracy: 0.4600\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.9264 - accuracy: 0.6486 - val_loss: 1.7488 - val_accuracy: 0.4700\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.9238 - accuracy: 0.6514 - val_loss: 1.7672 - val_accuracy: 0.4700\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9248 - accuracy: 0.6471 - val_loss: 1.7465 - val_accuracy: 0.4600\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9225 - accuracy: 0.6586 - val_loss: 1.7492 - val_accuracy: 0.4600\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9227 - accuracy: 0.6500 - val_loss: 1.7573 - val_accuracy: 0.4533\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9230 - accuracy: 0.6557 - val_loss: 1.7718 - val_accuracy: 0.4700\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9214 - accuracy: 0.6543 - val_loss: 1.7616 - val_accuracy: 0.4733\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9217 - accuracy: 0.6600 - val_loss: 1.7537 - val_accuracy: 0.4600\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9195 - accuracy: 0.6371 - val_loss: 1.7694 - val_accuracy: 0.4667\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.9195 - accuracy: 0.6557 - val_loss: 1.7569 - val_accuracy: 0.4600\n",
      "Epoch 283/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9172 - accuracy: 0.6600 - val_loss: 1.7506 - val_accuracy: 0.4533\n",
      "Epoch 284/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9200 - accuracy: 0.6543 - val_loss: 1.7657 - val_accuracy: 0.4667\n",
      "Epoch 285/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9180 - accuracy: 0.6557 - val_loss: 1.7767 - val_accuracy: 0.4667\n",
      "Epoch 286/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9160 - accuracy: 0.6543 - val_loss: 1.7662 - val_accuracy: 0.4667\n",
      "Epoch 287/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.9168 - accuracy: 0.6571 - val_loss: 1.7746 - val_accuracy: 0.4700\n",
      "Epoch 288/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9155 - accuracy: 0.6629 - val_loss: 1.7623 - val_accuracy: 0.4700\n",
      "Epoch 289/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.9146 - accuracy: 0.6586 - val_loss: 1.7688 - val_accuracy: 0.4633\n",
      "Epoch 290/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.9137 - accuracy: 0.6600 - val_loss: 1.7664 - val_accuracy: 0.4667\n",
      "Epoch 291/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9137 - accuracy: 0.6586 - val_loss: 1.7717 - val_accuracy: 0.4567\n",
      "Epoch 292/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9126 - accuracy: 0.6586 - val_loss: 1.7799 - val_accuracy: 0.4600\n",
      "Epoch 293/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.9118 - accuracy: 0.6586 - val_loss: 1.7826 - val_accuracy: 0.4567\n",
      "Epoch 294/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.9122 - accuracy: 0.6586 - val_loss: 1.7780 - val_accuracy: 0.4633\n",
      "Epoch 295/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9106 - accuracy: 0.6514 - val_loss: 1.7760 - val_accuracy: 0.4633\n",
      "Epoch 296/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9107 - accuracy: 0.6614 - val_loss: 1.7800 - val_accuracy: 0.4700\n",
      "Epoch 297/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9093 - accuracy: 0.6586 - val_loss: 1.7836 - val_accuracy: 0.4633\n",
      "Epoch 298/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.9086 - accuracy: 0.6600 - val_loss: 1.7872 - val_accuracy: 0.4633\n",
      "Epoch 299/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.9075 - accuracy: 0.6671 - val_loss: 1.7822 - val_accuracy: 0.4567\n",
      "Epoch 300/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9047 - accuracy: 0.6686 - val_loss: 1.7806 - val_accuracy: 0.4533\n",
      "Epoch 301/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.9069 - accuracy: 0.6614 - val_loss: 1.7813 - val_accuracy: 0.4667\n",
      "Epoch 302/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.9067 - accuracy: 0.6600 - val_loss: 1.7850 - val_accuracy: 0.4700\n",
      "Epoch 303/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9057 - accuracy: 0.6571 - val_loss: 1.7893 - val_accuracy: 0.4767\n",
      "Epoch 304/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.9041 - accuracy: 0.6657 - val_loss: 1.8153 - val_accuracy: 0.4633\n",
      "Epoch 305/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.9038 - accuracy: 0.6614 - val_loss: 1.7890 - val_accuracy: 0.4700\n",
      "Epoch 306/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.9032 - accuracy: 0.6629 - val_loss: 1.7945 - val_accuracy: 0.4633\n",
      "Epoch 307/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.9024 - accuracy: 0.6614 - val_loss: 1.8024 - val_accuracy: 0.4600\n",
      "Epoch 308/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9012 - accuracy: 0.6643 - val_loss: 1.7849 - val_accuracy: 0.4800\n",
      "Epoch 309/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8999 - accuracy: 0.6657 - val_loss: 1.7953 - val_accuracy: 0.4700\n",
      "Epoch 310/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.9001 - accuracy: 0.6643 - val_loss: 1.8169 - val_accuracy: 0.4600\n",
      "Epoch 311/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.8995 - accuracy: 0.6586 - val_loss: 1.8021 - val_accuracy: 0.4667\n",
      "Epoch 312/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.8995 - accuracy: 0.6614 - val_loss: 1.7978 - val_accuracy: 0.4767\n",
      "Epoch 313/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8981 - accuracy: 0.6586 - val_loss: 1.7962 - val_accuracy: 0.4600\n",
      "Epoch 314/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8977 - accuracy: 0.6686 - val_loss: 1.8114 - val_accuracy: 0.4567\n",
      "Epoch 315/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8972 - accuracy: 0.6643 - val_loss: 1.8188 - val_accuracy: 0.4600\n",
      "Epoch 316/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8970 - accuracy: 0.6629 - val_loss: 1.8259 - val_accuracy: 0.4633\n",
      "Epoch 317/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8963 - accuracy: 0.6686 - val_loss: 1.8227 - val_accuracy: 0.4667\n",
      "Epoch 318/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8946 - accuracy: 0.6600 - val_loss: 1.8297 - val_accuracy: 0.4567\n",
      "Epoch 319/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8951 - accuracy: 0.6600 - val_loss: 1.8106 - val_accuracy: 0.4667\n",
      "Epoch 320/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8932 - accuracy: 0.6686 - val_loss: 1.8153 - val_accuracy: 0.4600\n",
      "Epoch 321/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8934 - accuracy: 0.6671 - val_loss: 1.8174 - val_accuracy: 0.4667\n",
      "Epoch 322/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8941 - accuracy: 0.6671 - val_loss: 1.8120 - val_accuracy: 0.4600\n",
      "Epoch 323/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8927 - accuracy: 0.6714 - val_loss: 1.8199 - val_accuracy: 0.4633\n",
      "Epoch 324/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8916 - accuracy: 0.6729 - val_loss: 1.8208 - val_accuracy: 0.4767\n",
      "Epoch 325/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8914 - accuracy: 0.6743 - val_loss: 1.8181 - val_accuracy: 0.4700\n",
      "Epoch 326/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8905 - accuracy: 0.6729 - val_loss: 1.8267 - val_accuracy: 0.4667\n",
      "Epoch 327/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8894 - accuracy: 0.6643 - val_loss: 1.8249 - val_accuracy: 0.4600\n",
      "Epoch 328/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8893 - accuracy: 0.6700 - val_loss: 1.8352 - val_accuracy: 0.4733\n",
      "Epoch 329/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8884 - accuracy: 0.6686 - val_loss: 1.8314 - val_accuracy: 0.4633\n",
      "Epoch 330/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8879 - accuracy: 0.6700 - val_loss: 1.8387 - val_accuracy: 0.4633\n",
      "Epoch 331/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8882 - accuracy: 0.6657 - val_loss: 1.8389 - val_accuracy: 0.4567\n",
      "Epoch 332/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 0.8863 - accuracy: 0.6700 - val_loss: 1.8279 - val_accuracy: 0.4633\n",
      "Epoch 333/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8855 - accuracy: 0.6657 - val_loss: 1.8475 - val_accuracy: 0.4700\n",
      "Epoch 334/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8858 - accuracy: 0.6686 - val_loss: 1.8223 - val_accuracy: 0.4733\n",
      "Epoch 335/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.8850 - accuracy: 0.6700 - val_loss: 1.8261 - val_accuracy: 0.4733\n",
      "Epoch 336/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8834 - accuracy: 0.6757 - val_loss: 1.8407 - val_accuracy: 0.4733\n",
      "Epoch 337/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8840 - accuracy: 0.6700 - val_loss: 1.8441 - val_accuracy: 0.4733\n",
      "Epoch 338/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8828 - accuracy: 0.6686 - val_loss: 1.8412 - val_accuracy: 0.4733\n",
      "Epoch 339/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8831 - accuracy: 0.6743 - val_loss: 1.8522 - val_accuracy: 0.4600\n",
      "Epoch 340/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.8829 - accuracy: 0.6700 - val_loss: 1.8427 - val_accuracy: 0.4767\n",
      "Epoch 341/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8820 - accuracy: 0.6757 - val_loss: 1.8543 - val_accuracy: 0.4500\n",
      "Epoch 342/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.8802 - accuracy: 0.6714 - val_loss: 1.8448 - val_accuracy: 0.4600\n",
      "Epoch 343/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.8803 - accuracy: 0.6686 - val_loss: 1.8397 - val_accuracy: 0.4733\n",
      "Epoch 344/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.8786 - accuracy: 0.6800 - val_loss: 1.8410 - val_accuracy: 0.4800\n",
      "Epoch 345/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8786 - accuracy: 0.6771 - val_loss: 1.8518 - val_accuracy: 0.4633\n",
      "Epoch 346/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8780 - accuracy: 0.6729 - val_loss: 1.8442 - val_accuracy: 0.4733\n",
      "Epoch 347/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8784 - accuracy: 0.6771 - val_loss: 1.8524 - val_accuracy: 0.4633\n",
      "Epoch 348/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8770 - accuracy: 0.6743 - val_loss: 1.8630 - val_accuracy: 0.4700\n",
      "Epoch 349/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8763 - accuracy: 0.6743 - val_loss: 1.8419 - val_accuracy: 0.4767\n",
      "Epoch 350/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.8773 - accuracy: 0.6757 - val_loss: 1.8582 - val_accuracy: 0.4667\n",
      "Epoch 351/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8750 - accuracy: 0.6757 - val_loss: 1.8551 - val_accuracy: 0.4667\n",
      "Epoch 352/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.8756 - accuracy: 0.6643 - val_loss: 1.8566 - val_accuracy: 0.4600\n",
      "Epoch 353/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.8755 - accuracy: 0.6771 - val_loss: 1.8697 - val_accuracy: 0.4633\n",
      "Epoch 354/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.8748 - accuracy: 0.6757 - val_loss: 1.8730 - val_accuracy: 0.4700\n",
      "Epoch 355/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8727 - accuracy: 0.6786 - val_loss: 1.8658 - val_accuracy: 0.4800\n",
      "Epoch 356/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8721 - accuracy: 0.6771 - val_loss: 1.8660 - val_accuracy: 0.4700\n",
      "Epoch 357/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8726 - accuracy: 0.6729 - val_loss: 1.8630 - val_accuracy: 0.4700\n",
      "Epoch 358/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8725 - accuracy: 0.6757 - val_loss: 1.8632 - val_accuracy: 0.4800\n",
      "Epoch 359/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8720 - accuracy: 0.6771 - val_loss: 1.8782 - val_accuracy: 0.4733\n",
      "Epoch 360/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.8713 - accuracy: 0.6714 - val_loss: 1.8708 - val_accuracy: 0.4567\n",
      "Epoch 361/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8707 - accuracy: 0.6757 - val_loss: 1.8775 - val_accuracy: 0.4700\n",
      "Epoch 362/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8697 - accuracy: 0.6900 - val_loss: 1.8744 - val_accuracy: 0.4733\n",
      "Epoch 363/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8682 - accuracy: 0.6743 - val_loss: 1.8782 - val_accuracy: 0.4633\n",
      "Epoch 364/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8682 - accuracy: 0.6800 - val_loss: 1.8755 - val_accuracy: 0.4800\n",
      "Epoch 365/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8681 - accuracy: 0.6800 - val_loss: 1.8808 - val_accuracy: 0.4700\n",
      "Epoch 366/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8681 - accuracy: 0.6757 - val_loss: 1.8752 - val_accuracy: 0.4767\n",
      "Epoch 367/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8672 - accuracy: 0.6886 - val_loss: 1.8863 - val_accuracy: 0.4667\n",
      "Epoch 368/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8670 - accuracy: 0.6814 - val_loss: 1.8766 - val_accuracy: 0.4767\n",
      "Epoch 369/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8654 - accuracy: 0.6871 - val_loss: 1.9002 - val_accuracy: 0.4467\n",
      "Epoch 370/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8653 - accuracy: 0.6786 - val_loss: 1.8947 - val_accuracy: 0.4733\n",
      "Epoch 371/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8646 - accuracy: 0.6786 - val_loss: 1.8862 - val_accuracy: 0.4800\n",
      "Epoch 372/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8642 - accuracy: 0.6771 - val_loss: 1.8861 - val_accuracy: 0.4700\n",
      "Epoch 373/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8637 - accuracy: 0.6786 - val_loss: 1.9085 - val_accuracy: 0.4567\n",
      "Epoch 374/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8636 - accuracy: 0.6843 - val_loss: 1.8814 - val_accuracy: 0.4700\n",
      "Epoch 375/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8635 - accuracy: 0.6771 - val_loss: 1.8909 - val_accuracy: 0.4767\n",
      "Epoch 376/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8627 - accuracy: 0.6800 - val_loss: 1.8959 - val_accuracy: 0.4700\n",
      "Epoch 377/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8616 - accuracy: 0.6857 - val_loss: 1.8880 - val_accuracy: 0.4733\n",
      "Epoch 378/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8611 - accuracy: 0.6829 - val_loss: 1.8981 - val_accuracy: 0.4700\n",
      "Epoch 379/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8601 - accuracy: 0.6771 - val_loss: 1.8939 - val_accuracy: 0.4633\n",
      "Epoch 380/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8591 - accuracy: 0.6771 - val_loss: 1.9035 - val_accuracy: 0.4667\n",
      "Epoch 381/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8591 - accuracy: 0.6814 - val_loss: 1.9133 - val_accuracy: 0.4600\n",
      "Epoch 382/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8592 - accuracy: 0.6786 - val_loss: 1.8939 - val_accuracy: 0.4767\n",
      "Epoch 383/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8584 - accuracy: 0.6829 - val_loss: 1.8981 - val_accuracy: 0.4567\n",
      "Epoch 384/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8578 - accuracy: 0.6814 - val_loss: 1.8934 - val_accuracy: 0.4767\n",
      "Epoch 385/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8575 - accuracy: 0.6814 - val_loss: 1.9203 - val_accuracy: 0.4533\n",
      "Epoch 386/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8570 - accuracy: 0.6829 - val_loss: 1.9017 - val_accuracy: 0.4700\n",
      "Epoch 387/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8577 - accuracy: 0.6871 - val_loss: 1.9160 - val_accuracy: 0.4733\n",
      "Epoch 388/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8559 - accuracy: 0.6829 - val_loss: 1.9095 - val_accuracy: 0.4733\n",
      "Epoch 389/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8560 - accuracy: 0.6800 - val_loss: 1.9209 - val_accuracy: 0.4733\n",
      "Epoch 390/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8548 - accuracy: 0.6857 - val_loss: 1.9027 - val_accuracy: 0.4733\n",
      "Epoch 391/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8547 - accuracy: 0.6843 - val_loss: 1.9238 - val_accuracy: 0.4667\n",
      "Epoch 392/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8541 - accuracy: 0.6871 - val_loss: 1.9235 - val_accuracy: 0.4700\n",
      "Epoch 393/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8539 - accuracy: 0.6786 - val_loss: 1.9130 - val_accuracy: 0.4633\n",
      "Epoch 394/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8526 - accuracy: 0.6843 - val_loss: 1.9194 - val_accuracy: 0.4733\n",
      "Epoch 395/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.8521 - accuracy: 0.6871 - val_loss: 1.9191 - val_accuracy: 0.4733\n",
      "Epoch 396/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.8530 - accuracy: 0.6786 - val_loss: 1.9066 - val_accuracy: 0.4600\n",
      "Epoch 397/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8510 - accuracy: 0.6857 - val_loss: 1.9277 - val_accuracy: 0.4767\n",
      "Epoch 398/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8508 - accuracy: 0.6886 - val_loss: 1.9295 - val_accuracy: 0.4633\n",
      "Epoch 399/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8497 - accuracy: 0.6871 - val_loss: 1.9344 - val_accuracy: 0.4667\n",
      "Epoch 400/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8497 - accuracy: 0.6800 - val_loss: 1.9159 - val_accuracy: 0.4700\n",
      "Epoch 401/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8509 - accuracy: 0.6886 - val_loss: 1.9377 - val_accuracy: 0.4667\n",
      "Epoch 402/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8493 - accuracy: 0.6829 - val_loss: 1.9410 - val_accuracy: 0.4667\n",
      "Epoch 403/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8490 - accuracy: 0.6871 - val_loss: 1.9380 - val_accuracy: 0.4667\n",
      "Epoch 404/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8490 - accuracy: 0.6814 - val_loss: 1.9325 - val_accuracy: 0.4533\n",
      "Epoch 405/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8490 - accuracy: 0.6914 - val_loss: 1.9375 - val_accuracy: 0.4667\n",
      "Epoch 406/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8470 - accuracy: 0.6829 - val_loss: 1.9326 - val_accuracy: 0.4767\n",
      "Epoch 407/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8469 - accuracy: 0.6900 - val_loss: 1.9379 - val_accuracy: 0.4667\n",
      "Epoch 408/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8463 - accuracy: 0.6771 - val_loss: 1.9469 - val_accuracy: 0.4667\n",
      "Epoch 409/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8462 - accuracy: 0.6914 - val_loss: 1.9357 - val_accuracy: 0.4567\n",
      "Epoch 410/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8456 - accuracy: 0.6900 - val_loss: 1.9473 - val_accuracy: 0.4633\n",
      "Epoch 411/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8459 - accuracy: 0.6914 - val_loss: 1.9545 - val_accuracy: 0.4667\n",
      "Epoch 412/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8435 - accuracy: 0.6886 - val_loss: 1.9512 - val_accuracy: 0.4667\n",
      "Epoch 413/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8437 - accuracy: 0.6871 - val_loss: 1.9589 - val_accuracy: 0.4600\n",
      "Epoch 414/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8421 - accuracy: 0.6814 - val_loss: 1.9314 - val_accuracy: 0.4733\n",
      "Epoch 415/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8440 - accuracy: 0.6871 - val_loss: 1.9495 - val_accuracy: 0.4733\n",
      "Epoch 416/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8427 - accuracy: 0.6857 - val_loss: 1.9610 - val_accuracy: 0.4633\n",
      "Epoch 417/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8409 - accuracy: 0.6886 - val_loss: 1.9462 - val_accuracy: 0.4667\n",
      "Epoch 418/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8414 - accuracy: 0.6871 - val_loss: 1.9683 - val_accuracy: 0.4633\n",
      "Epoch 419/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8412 - accuracy: 0.6886 - val_loss: 1.9715 - val_accuracy: 0.4633\n",
      "Epoch 420/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8403 - accuracy: 0.6843 - val_loss: 1.9534 - val_accuracy: 0.4700\n",
      "Epoch 421/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8400 - accuracy: 0.6914 - val_loss: 1.9577 - val_accuracy: 0.4733\n",
      "Epoch 422/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8392 - accuracy: 0.6843 - val_loss: 1.9570 - val_accuracy: 0.4667\n",
      "Epoch 423/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8388 - accuracy: 0.6929 - val_loss: 1.9787 - val_accuracy: 0.4600\n",
      "Epoch 424/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8385 - accuracy: 0.6900 - val_loss: 1.9734 - val_accuracy: 0.4667\n",
      "Epoch 425/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8383 - accuracy: 0.6871 - val_loss: 1.9630 - val_accuracy: 0.4700\n",
      "Epoch 426/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.8378 - accuracy: 0.6914 - val_loss: 1.9732 - val_accuracy: 0.4600\n",
      "Epoch 427/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8375 - accuracy: 0.6857 - val_loss: 1.9589 - val_accuracy: 0.4733\n",
      "Epoch 428/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8374 - accuracy: 0.6943 - val_loss: 1.9788 - val_accuracy: 0.4600\n",
      "Epoch 429/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8368 - accuracy: 0.6929 - val_loss: 1.9645 - val_accuracy: 0.4700\n",
      "Epoch 430/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8354 - accuracy: 0.6900 - val_loss: 1.9667 - val_accuracy: 0.4633\n",
      "Epoch 431/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8343 - accuracy: 0.6914 - val_loss: 1.9710 - val_accuracy: 0.4633\n",
      "Epoch 432/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8350 - accuracy: 0.6943 - val_loss: 1.9883 - val_accuracy: 0.4567\n",
      "Epoch 433/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8357 - accuracy: 0.6914 - val_loss: 1.9808 - val_accuracy: 0.4667\n",
      "Epoch 434/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8338 - accuracy: 0.6943 - val_loss: 1.9860 - val_accuracy: 0.4633\n",
      "Epoch 435/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8336 - accuracy: 0.6886 - val_loss: 1.9798 - val_accuracy: 0.4667\n",
      "Epoch 436/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8337 - accuracy: 0.6943 - val_loss: 1.9913 - val_accuracy: 0.4733\n",
      "Epoch 437/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.8334 - accuracy: 0.6900 - val_loss: 1.9863 - val_accuracy: 0.4700\n",
      "Epoch 438/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.8324 - accuracy: 0.6871 - val_loss: 1.9801 - val_accuracy: 0.4633\n",
      "Epoch 439/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8319 - accuracy: 0.6914 - val_loss: 2.0051 - val_accuracy: 0.4600\n",
      "Epoch 440/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.8317 - accuracy: 0.6929 - val_loss: 1.9966 - val_accuracy: 0.4633\n",
      "Epoch 441/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8321 - accuracy: 0.6886 - val_loss: 1.9965 - val_accuracy: 0.4667\n",
      "Epoch 442/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 107us/step - loss: 0.8315 - accuracy: 0.6943 - val_loss: 1.9983 - val_accuracy: 0.4633\n",
      "Epoch 443/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8310 - accuracy: 0.6943 - val_loss: 2.0040 - val_accuracy: 0.4633\n",
      "Epoch 444/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8308 - accuracy: 0.6943 - val_loss: 2.0084 - val_accuracy: 0.4633\n",
      "Epoch 445/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8298 - accuracy: 0.6900 - val_loss: 1.9887 - val_accuracy: 0.4567\n",
      "Epoch 446/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8300 - accuracy: 0.6871 - val_loss: 1.9996 - val_accuracy: 0.4600\n",
      "Epoch 447/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8285 - accuracy: 0.6914 - val_loss: 2.0227 - val_accuracy: 0.4600\n",
      "Epoch 448/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8276 - accuracy: 0.6929 - val_loss: 1.9908 - val_accuracy: 0.4633\n",
      "Epoch 449/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8274 - accuracy: 0.6914 - val_loss: 2.0149 - val_accuracy: 0.4600\n",
      "Epoch 450/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8269 - accuracy: 0.6986 - val_loss: 2.0076 - val_accuracy: 0.4633\n",
      "Epoch 451/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8259 - accuracy: 0.6914 - val_loss: 2.0053 - val_accuracy: 0.4567\n",
      "Epoch 452/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8258 - accuracy: 0.6914 - val_loss: 2.0008 - val_accuracy: 0.4567\n",
      "Epoch 453/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8243 - accuracy: 0.6957 - val_loss: 2.0081 - val_accuracy: 0.4567\n",
      "Epoch 454/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8248 - accuracy: 0.6929 - val_loss: 2.0135 - val_accuracy: 0.4533\n",
      "Epoch 455/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8237 - accuracy: 0.6914 - val_loss: 2.0219 - val_accuracy: 0.4533\n",
      "Epoch 456/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8240 - accuracy: 0.6957 - val_loss: 2.0113 - val_accuracy: 0.4633\n",
      "Epoch 457/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8225 - accuracy: 0.6929 - val_loss: 2.0086 - val_accuracy: 0.4533\n",
      "Epoch 458/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8220 - accuracy: 0.7000 - val_loss: 2.0127 - val_accuracy: 0.4600\n",
      "Epoch 459/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8215 - accuracy: 0.6929 - val_loss: 2.0234 - val_accuracy: 0.4600\n",
      "Epoch 460/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8211 - accuracy: 0.6971 - val_loss: 2.0259 - val_accuracy: 0.4567\n",
      "Epoch 461/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8213 - accuracy: 0.6943 - val_loss: 2.0171 - val_accuracy: 0.4567\n",
      "Epoch 462/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8203 - accuracy: 0.6943 - val_loss: 2.0181 - val_accuracy: 0.4567\n",
      "Epoch 463/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8195 - accuracy: 0.7000 - val_loss: 2.0206 - val_accuracy: 0.4567\n",
      "Epoch 464/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.8194 - accuracy: 0.6971 - val_loss: 2.0266 - val_accuracy: 0.4567\n",
      "Epoch 465/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.8187 - accuracy: 0.6971 - val_loss: 2.0385 - val_accuracy: 0.4533\n",
      "Epoch 466/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8189 - accuracy: 0.6986 - val_loss: 2.0331 - val_accuracy: 0.4567\n",
      "Epoch 467/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8184 - accuracy: 0.6957 - val_loss: 2.0322 - val_accuracy: 0.4600\n",
      "Epoch 468/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.8164 - accuracy: 0.6986 - val_loss: 2.0289 - val_accuracy: 0.4567\n",
      "Epoch 469/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.8175 - accuracy: 0.7000 - val_loss: 2.0366 - val_accuracy: 0.4600\n",
      "Epoch 470/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8172 - accuracy: 0.6971 - val_loss: 2.0269 - val_accuracy: 0.4567\n",
      "Epoch 471/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8159 - accuracy: 0.6971 - val_loss: 2.0207 - val_accuracy: 0.4600\n",
      "Epoch 472/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8159 - accuracy: 0.6971 - val_loss: 2.0347 - val_accuracy: 0.4567\n",
      "Epoch 473/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.8157 - accuracy: 0.7014 - val_loss: 2.0378 - val_accuracy: 0.4567\n",
      "Epoch 474/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8134 - accuracy: 0.6957 - val_loss: 2.0226 - val_accuracy: 0.4567\n",
      "Epoch 475/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8134 - accuracy: 0.6986 - val_loss: 2.0352 - val_accuracy: 0.4600\n",
      "Epoch 476/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8138 - accuracy: 0.6986 - val_loss: 2.0359 - val_accuracy: 0.4533\n",
      "Epoch 477/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.8129 - accuracy: 0.7000 - val_loss: 2.0345 - val_accuracy: 0.4533\n",
      "Epoch 478/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8127 - accuracy: 0.6971 - val_loss: 2.0405 - val_accuracy: 0.4567\n",
      "Epoch 479/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.8122 - accuracy: 0.6971 - val_loss: 2.0427 - val_accuracy: 0.4533\n",
      "Epoch 480/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.8118 - accuracy: 0.7000 - val_loss: 2.0459 - val_accuracy: 0.4567\n",
      "Epoch 481/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8118 - accuracy: 0.7000 - val_loss: 2.0377 - val_accuracy: 0.4600\n",
      "Epoch 482/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8107 - accuracy: 0.7014 - val_loss: 2.0337 - val_accuracy: 0.4533\n",
      "Epoch 483/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8107 - accuracy: 0.7014 - val_loss: 2.0346 - val_accuracy: 0.4500\n",
      "Epoch 484/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8093 - accuracy: 0.6986 - val_loss: 2.0545 - val_accuracy: 0.4600\n",
      "Epoch 485/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.8100 - accuracy: 0.6971 - val_loss: 2.0457 - val_accuracy: 0.4600\n",
      "Epoch 486/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8098 - accuracy: 0.6971 - val_loss: 2.0466 - val_accuracy: 0.4533\n",
      "Epoch 487/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8091 - accuracy: 0.6986 - val_loss: 2.0365 - val_accuracy: 0.4533\n",
      "Epoch 488/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8087 - accuracy: 0.6971 - val_loss: 2.0588 - val_accuracy: 0.4633\n",
      "Epoch 489/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8084 - accuracy: 0.7014 - val_loss: 2.0583 - val_accuracy: 0.4533\n",
      "Epoch 490/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8075 - accuracy: 0.6957 - val_loss: 2.0561 - val_accuracy: 0.4500\n",
      "Epoch 491/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8071 - accuracy: 0.7000 - val_loss: 2.0690 - val_accuracy: 0.4500\n",
      "Epoch 492/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8071 - accuracy: 0.6971 - val_loss: 2.0561 - val_accuracy: 0.4467\n",
      "Epoch 493/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.8063 - accuracy: 0.6986 - val_loss: 2.0683 - val_accuracy: 0.4433\n",
      "Epoch 494/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8059 - accuracy: 0.7000 - val_loss: 2.0622 - val_accuracy: 0.4433\n",
      "Epoch 495/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.8046 - accuracy: 0.7029 - val_loss: 2.0651 - val_accuracy: 0.4433\n",
      "Epoch 496/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8056 - accuracy: 0.7000 - val_loss: 2.0528 - val_accuracy: 0.4567\n",
      "Epoch 497/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.8050 - accuracy: 0.7043 - val_loss: 2.0571 - val_accuracy: 0.4467\n",
      "Epoch 498/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8041 - accuracy: 0.6986 - val_loss: 2.0765 - val_accuracy: 0.4533\n",
      "Epoch 499/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.8047 - accuracy: 0.7029 - val_loss: 2.0829 - val_accuracy: 0.4400\n",
      "Epoch 500/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8036 - accuracy: 0.7014 - val_loss: 2.0651 - val_accuracy: 0.4467\n",
      "Epoch 501/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.8036 - accuracy: 0.6971 - val_loss: 2.0719 - val_accuracy: 0.4400\n",
      "Epoch 502/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8030 - accuracy: 0.7000 - val_loss: 2.0715 - val_accuracy: 0.4533\n",
      "Epoch 503/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8020 - accuracy: 0.6986 - val_loss: 2.0675 - val_accuracy: 0.4500\n",
      "Epoch 504/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8026 - accuracy: 0.7043 - val_loss: 2.0795 - val_accuracy: 0.4567\n",
      "Epoch 505/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.8007 - accuracy: 0.7014 - val_loss: 2.0632 - val_accuracy: 0.4400\n",
      "Epoch 506/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.8020 - accuracy: 0.7057 - val_loss: 2.0773 - val_accuracy: 0.4467\n",
      "Epoch 507/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.8007 - accuracy: 0.7014 - val_loss: 2.0787 - val_accuracy: 0.4433\n",
      "Epoch 508/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8006 - accuracy: 0.7000 - val_loss: 2.0796 - val_accuracy: 0.4433\n",
      "Epoch 509/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.8007 - accuracy: 0.7014 - val_loss: 2.0743 - val_accuracy: 0.4400\n",
      "Epoch 510/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.8000 - accuracy: 0.7029 - val_loss: 2.0715 - val_accuracy: 0.4433\n",
      "Epoch 511/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7987 - accuracy: 0.7071 - val_loss: 2.0907 - val_accuracy: 0.4467\n",
      "Epoch 512/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7993 - accuracy: 0.7043 - val_loss: 2.0757 - val_accuracy: 0.4400\n",
      "Epoch 513/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7989 - accuracy: 0.7029 - val_loss: 2.0888 - val_accuracy: 0.4367\n",
      "Epoch 514/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7994 - accuracy: 0.7000 - val_loss: 2.0922 - val_accuracy: 0.4467\n",
      "Epoch 515/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7983 - accuracy: 0.7086 - val_loss: 2.0895 - val_accuracy: 0.4400\n",
      "Epoch 516/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7971 - accuracy: 0.7014 - val_loss: 2.1048 - val_accuracy: 0.4433\n",
      "Epoch 517/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7972 - accuracy: 0.6957 - val_loss: 2.0938 - val_accuracy: 0.4500\n",
      "Epoch 518/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7963 - accuracy: 0.7043 - val_loss: 2.0858 - val_accuracy: 0.4433\n",
      "Epoch 519/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7965 - accuracy: 0.7014 - val_loss: 2.0936 - val_accuracy: 0.4500\n",
      "Epoch 520/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7956 - accuracy: 0.7071 - val_loss: 2.0995 - val_accuracy: 0.4500\n",
      "Epoch 521/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7956 - accuracy: 0.7029 - val_loss: 2.0892 - val_accuracy: 0.4400\n",
      "Epoch 522/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.7945 - accuracy: 0.7057 - val_loss: 2.1041 - val_accuracy: 0.4567\n",
      "Epoch 523/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.7949 - accuracy: 0.7057 - val_loss: 2.1120 - val_accuracy: 0.4533\n",
      "Epoch 524/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7942 - accuracy: 0.7043 - val_loss: 2.1054 - val_accuracy: 0.4500\n",
      "Epoch 525/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7936 - accuracy: 0.7086 - val_loss: 2.1023 - val_accuracy: 0.4533\n",
      "Epoch 526/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7926 - accuracy: 0.7043 - val_loss: 2.0988 - val_accuracy: 0.4500\n",
      "Epoch 527/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7937 - accuracy: 0.7086 - val_loss: 2.0972 - val_accuracy: 0.4400\n",
      "Epoch 528/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7926 - accuracy: 0.7086 - val_loss: 2.1059 - val_accuracy: 0.4500\n",
      "Epoch 529/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7921 - accuracy: 0.7000 - val_loss: 2.1102 - val_accuracy: 0.4367\n",
      "Epoch 530/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7924 - accuracy: 0.7057 - val_loss: 2.1072 - val_accuracy: 0.4500\n",
      "Epoch 531/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7919 - accuracy: 0.7114 - val_loss: 2.1040 - val_accuracy: 0.4433\n",
      "Epoch 532/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7913 - accuracy: 0.7057 - val_loss: 2.1192 - val_accuracy: 0.4400\n",
      "Epoch 533/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7911 - accuracy: 0.7014 - val_loss: 2.1123 - val_accuracy: 0.4433\n",
      "Epoch 534/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7908 - accuracy: 0.7100 - val_loss: 2.1124 - val_accuracy: 0.4367\n",
      "Epoch 535/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7897 - accuracy: 0.7071 - val_loss: 2.1208 - val_accuracy: 0.4367\n",
      "Epoch 536/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7894 - accuracy: 0.7086 - val_loss: 2.1127 - val_accuracy: 0.4367\n",
      "Epoch 537/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7898 - accuracy: 0.7071 - val_loss: 2.1188 - val_accuracy: 0.4367\n",
      "Epoch 538/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7896 - accuracy: 0.7029 - val_loss: 2.1068 - val_accuracy: 0.4400\n",
      "Epoch 539/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7887 - accuracy: 0.7114 - val_loss: 2.1159 - val_accuracy: 0.4400\n",
      "Epoch 540/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7892 - accuracy: 0.7071 - val_loss: 2.1244 - val_accuracy: 0.4400\n",
      "Epoch 541/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7884 - accuracy: 0.7057 - val_loss: 2.1121 - val_accuracy: 0.4400\n",
      "Epoch 542/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7883 - accuracy: 0.7129 - val_loss: 2.1270 - val_accuracy: 0.4400\n",
      "Epoch 543/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7872 - accuracy: 0.7100 - val_loss: 2.1210 - val_accuracy: 0.4367\n",
      "Epoch 544/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7876 - accuracy: 0.7143 - val_loss: 2.1280 - val_accuracy: 0.4400\n",
      "Epoch 545/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7863 - accuracy: 0.7043 - val_loss: 2.1358 - val_accuracy: 0.4400\n",
      "Epoch 546/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7867 - accuracy: 0.7100 - val_loss: 2.1341 - val_accuracy: 0.4367\n",
      "Epoch 547/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7855 - accuracy: 0.7071 - val_loss: 2.1430 - val_accuracy: 0.4400\n",
      "Epoch 548/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7854 - accuracy: 0.7100 - val_loss: 2.1303 - val_accuracy: 0.4367\n",
      "Epoch 549/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7857 - accuracy: 0.7086 - val_loss: 2.1452 - val_accuracy: 0.4400\n",
      "Epoch 550/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7850 - accuracy: 0.7086 - val_loss: 2.1260 - val_accuracy: 0.4367\n",
      "Epoch 551/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7856 - accuracy: 0.7071 - val_loss: 2.1386 - val_accuracy: 0.4400\n",
      "Epoch 552/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 106us/step - loss: 0.7844 - accuracy: 0.7100 - val_loss: 2.1273 - val_accuracy: 0.4367\n",
      "Epoch 553/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7840 - accuracy: 0.7071 - val_loss: 2.1385 - val_accuracy: 0.4433\n",
      "Epoch 554/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7832 - accuracy: 0.7114 - val_loss: 2.1287 - val_accuracy: 0.4500\n",
      "Epoch 555/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7838 - accuracy: 0.7100 - val_loss: 2.1360 - val_accuracy: 0.4300\n",
      "Epoch 556/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7829 - accuracy: 0.7086 - val_loss: 2.1421 - val_accuracy: 0.4367\n",
      "Epoch 557/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7824 - accuracy: 0.7143 - val_loss: 2.1317 - val_accuracy: 0.4400\n",
      "Epoch 558/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7823 - accuracy: 0.7129 - val_loss: 2.1408 - val_accuracy: 0.4333\n",
      "Epoch 559/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7821 - accuracy: 0.7100 - val_loss: 2.1560 - val_accuracy: 0.4467\n",
      "Epoch 560/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7819 - accuracy: 0.7143 - val_loss: 2.1276 - val_accuracy: 0.4400\n",
      "Epoch 561/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7811 - accuracy: 0.7143 - val_loss: 2.1453 - val_accuracy: 0.4400\n",
      "Epoch 562/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7814 - accuracy: 0.7129 - val_loss: 2.1502 - val_accuracy: 0.4400\n",
      "Epoch 563/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.7802 - accuracy: 0.7143 - val_loss: 2.1508 - val_accuracy: 0.4433\n",
      "Epoch 564/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.7799 - accuracy: 0.7129 - val_loss: 2.1532 - val_accuracy: 0.4400\n",
      "Epoch 565/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7805 - accuracy: 0.7086 - val_loss: 2.1607 - val_accuracy: 0.4400\n",
      "Epoch 566/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7792 - accuracy: 0.7157 - val_loss: 2.1597 - val_accuracy: 0.4400\n",
      "Epoch 567/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7786 - accuracy: 0.7071 - val_loss: 2.1544 - val_accuracy: 0.4400\n",
      "Epoch 568/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7793 - accuracy: 0.7143 - val_loss: 2.1568 - val_accuracy: 0.4433\n",
      "Epoch 569/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7791 - accuracy: 0.7114 - val_loss: 2.1513 - val_accuracy: 0.4400\n",
      "Epoch 570/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7780 - accuracy: 0.7100 - val_loss: 2.1532 - val_accuracy: 0.4333\n",
      "Epoch 571/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7774 - accuracy: 0.7143 - val_loss: 2.1437 - val_accuracy: 0.4400\n",
      "Epoch 572/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7780 - accuracy: 0.7129 - val_loss: 2.1625 - val_accuracy: 0.4433\n",
      "Epoch 573/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7771 - accuracy: 0.7186 - val_loss: 2.1598 - val_accuracy: 0.4333\n",
      "Epoch 574/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7772 - accuracy: 0.7157 - val_loss: 2.1697 - val_accuracy: 0.4367\n",
      "Epoch 575/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7766 - accuracy: 0.7143 - val_loss: 2.1905 - val_accuracy: 0.4433\n",
      "Epoch 576/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7773 - accuracy: 0.7114 - val_loss: 2.1739 - val_accuracy: 0.4400\n",
      "Epoch 577/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7754 - accuracy: 0.7143 - val_loss: 2.1797 - val_accuracy: 0.4400\n",
      "Epoch 578/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7764 - accuracy: 0.7143 - val_loss: 2.1741 - val_accuracy: 0.4433\n",
      "Epoch 579/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7746 - accuracy: 0.7071 - val_loss: 2.1836 - val_accuracy: 0.4367\n",
      "Epoch 580/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7750 - accuracy: 0.7114 - val_loss: 2.1708 - val_accuracy: 0.4367\n",
      "Epoch 581/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7748 - accuracy: 0.7071 - val_loss: 2.1801 - val_accuracy: 0.4400\n",
      "Epoch 582/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7747 - accuracy: 0.7114 - val_loss: 2.1832 - val_accuracy: 0.4400\n",
      "Epoch 583/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7726 - accuracy: 0.7143 - val_loss: 2.1898 - val_accuracy: 0.4367\n",
      "Epoch 584/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7751 - accuracy: 0.7114 - val_loss: 2.1919 - val_accuracy: 0.4433\n",
      "Epoch 585/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7737 - accuracy: 0.7100 - val_loss: 2.1855 - val_accuracy: 0.4367\n",
      "Epoch 586/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7731 - accuracy: 0.7157 - val_loss: 2.1855 - val_accuracy: 0.4367\n",
      "Epoch 587/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7733 - accuracy: 0.7157 - val_loss: 2.1905 - val_accuracy: 0.4367\n",
      "Epoch 588/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7720 - accuracy: 0.7143 - val_loss: 2.1880 - val_accuracy: 0.4333\n",
      "Epoch 589/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7726 - accuracy: 0.7143 - val_loss: 2.1930 - val_accuracy: 0.4467\n",
      "Epoch 590/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7711 - accuracy: 0.7129 - val_loss: 2.1858 - val_accuracy: 0.4400\n",
      "Epoch 591/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7721 - accuracy: 0.7157 - val_loss: 2.1913 - val_accuracy: 0.4400\n",
      "Epoch 592/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7714 - accuracy: 0.7171 - val_loss: 2.1979 - val_accuracy: 0.4400\n",
      "Epoch 593/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7715 - accuracy: 0.7129 - val_loss: 2.2003 - val_accuracy: 0.4333\n",
      "Epoch 594/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7715 - accuracy: 0.7100 - val_loss: 2.2059 - val_accuracy: 0.4400\n",
      "Epoch 595/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7707 - accuracy: 0.7129 - val_loss: 2.1941 - val_accuracy: 0.4367\n",
      "Epoch 596/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7693 - accuracy: 0.7100 - val_loss: 2.2038 - val_accuracy: 0.4400\n",
      "Epoch 597/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7706 - accuracy: 0.7114 - val_loss: 2.1945 - val_accuracy: 0.4333\n",
      "Epoch 598/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7700 - accuracy: 0.7157 - val_loss: 2.2072 - val_accuracy: 0.4400\n",
      "Epoch 599/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7692 - accuracy: 0.7129 - val_loss: 2.1982 - val_accuracy: 0.4300\n",
      "Epoch 600/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7700 - accuracy: 0.7157 - val_loss: 2.1930 - val_accuracy: 0.4333\n",
      "Epoch 601/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7684 - accuracy: 0.7171 - val_loss: 2.2061 - val_accuracy: 0.4333\n",
      "Epoch 602/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7677 - accuracy: 0.7143 - val_loss: 2.2091 - val_accuracy: 0.4367\n",
      "Epoch 603/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7672 - accuracy: 0.7157 - val_loss: 2.2106 - val_accuracy: 0.4367\n",
      "Epoch 604/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7670 - accuracy: 0.7143 - val_loss: 2.2223 - val_accuracy: 0.4400\n",
      "Epoch 605/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.7682 - accuracy: 0.7171 - val_loss: 2.2144 - val_accuracy: 0.4500\n",
      "Epoch 606/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.7671 - accuracy: 0.7157 - val_loss: 2.2177 - val_accuracy: 0.4400\n",
      "Epoch 607/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7666 - accuracy: 0.7143 - val_loss: 2.2113 - val_accuracy: 0.4367\n",
      "Epoch 608/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7664 - accuracy: 0.7114 - val_loss: 2.2167 - val_accuracy: 0.4400\n",
      "Epoch 609/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7660 - accuracy: 0.7143 - val_loss: 2.2131 - val_accuracy: 0.4333\n",
      "Epoch 610/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7663 - accuracy: 0.7114 - val_loss: 2.2237 - val_accuracy: 0.4400\n",
      "Epoch 611/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7660 - accuracy: 0.7100 - val_loss: 2.2362 - val_accuracy: 0.4500\n",
      "Epoch 612/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7650 - accuracy: 0.7129 - val_loss: 2.2279 - val_accuracy: 0.4367\n",
      "Epoch 613/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7653 - accuracy: 0.7143 - val_loss: 2.2286 - val_accuracy: 0.4433\n",
      "Epoch 614/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7649 - accuracy: 0.7114 - val_loss: 2.2211 - val_accuracy: 0.4400\n",
      "Epoch 615/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7657 - accuracy: 0.7129 - val_loss: 2.2163 - val_accuracy: 0.4300\n",
      "Epoch 616/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7648 - accuracy: 0.7171 - val_loss: 2.2246 - val_accuracy: 0.4333\n",
      "Epoch 617/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7638 - accuracy: 0.7171 - val_loss: 2.2260 - val_accuracy: 0.4267\n",
      "Epoch 618/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7639 - accuracy: 0.7143 - val_loss: 2.2232 - val_accuracy: 0.4367\n",
      "Epoch 619/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7627 - accuracy: 0.7143 - val_loss: 2.2279 - val_accuracy: 0.4333\n",
      "Epoch 620/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7625 - accuracy: 0.7171 - val_loss: 2.2199 - val_accuracy: 0.4300\n",
      "Epoch 621/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7636 - accuracy: 0.7157 - val_loss: 2.2457 - val_accuracy: 0.4400\n",
      "Epoch 622/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7625 - accuracy: 0.7157 - val_loss: 2.2379 - val_accuracy: 0.4367\n",
      "Epoch 623/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7625 - accuracy: 0.7171 - val_loss: 2.2409 - val_accuracy: 0.4367\n",
      "Epoch 624/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7624 - accuracy: 0.7171 - val_loss: 2.2369 - val_accuracy: 0.4400\n",
      "Epoch 625/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7621 - accuracy: 0.7143 - val_loss: 2.2352 - val_accuracy: 0.4300\n",
      "Epoch 626/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7610 - accuracy: 0.7157 - val_loss: 2.2429 - val_accuracy: 0.4400\n",
      "Epoch 627/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7607 - accuracy: 0.7129 - val_loss: 2.2401 - val_accuracy: 0.4400\n",
      "Epoch 628/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7613 - accuracy: 0.7171 - val_loss: 2.2523 - val_accuracy: 0.4433\n",
      "Epoch 629/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7597 - accuracy: 0.7143 - val_loss: 2.2506 - val_accuracy: 0.4433\n",
      "Epoch 630/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7609 - accuracy: 0.7171 - val_loss: 2.2420 - val_accuracy: 0.4333\n",
      "Epoch 631/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7595 - accuracy: 0.7129 - val_loss: 2.2839 - val_accuracy: 0.4433\n",
      "Epoch 632/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7597 - accuracy: 0.7186 - val_loss: 2.2453 - val_accuracy: 0.4400\n",
      "Epoch 633/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7579 - accuracy: 0.7200 - val_loss: 2.2393 - val_accuracy: 0.4300\n",
      "Epoch 634/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7598 - accuracy: 0.7186 - val_loss: 2.2398 - val_accuracy: 0.4333\n",
      "Epoch 635/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7592 - accuracy: 0.7129 - val_loss: 2.2476 - val_accuracy: 0.4400\n",
      "Epoch 636/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7585 - accuracy: 0.7171 - val_loss: 2.2549 - val_accuracy: 0.4333\n",
      "Epoch 637/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7581 - accuracy: 0.7186 - val_loss: 2.2639 - val_accuracy: 0.4400\n",
      "Epoch 638/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7584 - accuracy: 0.7143 - val_loss: 2.2602 - val_accuracy: 0.4367\n",
      "Epoch 639/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7572 - accuracy: 0.7157 - val_loss: 2.2764 - val_accuracy: 0.4433\n",
      "Epoch 640/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7579 - accuracy: 0.7171 - val_loss: 2.2564 - val_accuracy: 0.4367\n",
      "Epoch 641/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7581 - accuracy: 0.7186 - val_loss: 2.2637 - val_accuracy: 0.4367\n",
      "Epoch 642/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7565 - accuracy: 0.7214 - val_loss: 2.2507 - val_accuracy: 0.4367\n",
      "Epoch 643/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7569 - accuracy: 0.7200 - val_loss: 2.2745 - val_accuracy: 0.4400\n",
      "Epoch 644/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7575 - accuracy: 0.7157 - val_loss: 2.2539 - val_accuracy: 0.4400\n",
      "Epoch 645/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7565 - accuracy: 0.7200 - val_loss: 2.2779 - val_accuracy: 0.4400\n",
      "Epoch 646/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7560 - accuracy: 0.7157 - val_loss: 2.2557 - val_accuracy: 0.4400\n",
      "Epoch 647/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.7557 - accuracy: 0.7171 - val_loss: 2.2690 - val_accuracy: 0.4367\n",
      "Epoch 648/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.7560 - accuracy: 0.7157 - val_loss: 2.2648 - val_accuracy: 0.4367\n",
      "Epoch 649/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.7557 - accuracy: 0.7143 - val_loss: 2.2709 - val_accuracy: 0.4300\n",
      "Epoch 650/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7549 - accuracy: 0.7186 - val_loss: 2.2698 - val_accuracy: 0.4433\n",
      "Epoch 651/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7545 - accuracy: 0.7143 - val_loss: 2.2577 - val_accuracy: 0.4333\n",
      "Epoch 652/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7541 - accuracy: 0.7171 - val_loss: 2.2733 - val_accuracy: 0.4367\n",
      "Epoch 653/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7535 - accuracy: 0.7171 - val_loss: 2.2809 - val_accuracy: 0.4400\n",
      "Epoch 654/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7533 - accuracy: 0.7214 - val_loss: 2.2715 - val_accuracy: 0.4300\n",
      "Epoch 655/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7529 - accuracy: 0.7100 - val_loss: 2.2772 - val_accuracy: 0.4400\n",
      "Epoch 656/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7527 - accuracy: 0.7186 - val_loss: 2.2889 - val_accuracy: 0.4433\n",
      "Epoch 657/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7537 - accuracy: 0.7214 - val_loss: 2.2764 - val_accuracy: 0.4367\n",
      "Epoch 658/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7525 - accuracy: 0.7200 - val_loss: 2.2795 - val_accuracy: 0.4333\n",
      "Epoch 659/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7522 - accuracy: 0.7200 - val_loss: 2.2947 - val_accuracy: 0.4333\n",
      "Epoch 660/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7526 - accuracy: 0.7186 - val_loss: 2.2815 - val_accuracy: 0.4300\n",
      "Epoch 661/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.7609 - accuracy: 0.71 - 0s 110us/step - loss: 0.7518 - accuracy: 0.7186 - val_loss: 2.2933 - val_accuracy: 0.4333\n",
      "Epoch 662/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 110us/step - loss: 0.7509 - accuracy: 0.7171 - val_loss: 2.2965 - val_accuracy: 0.4367\n",
      "Epoch 663/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7514 - accuracy: 0.7186 - val_loss: 2.2891 - val_accuracy: 0.4367\n",
      "Epoch 664/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7511 - accuracy: 0.7186 - val_loss: 2.2886 - val_accuracy: 0.4367\n",
      "Epoch 665/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7505 - accuracy: 0.7243 - val_loss: 2.3024 - val_accuracy: 0.4367\n",
      "Epoch 666/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7506 - accuracy: 0.7243 - val_loss: 2.3042 - val_accuracy: 0.4367\n",
      "Epoch 667/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7498 - accuracy: 0.7157 - val_loss: 2.2911 - val_accuracy: 0.4333\n",
      "Epoch 668/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7511 - accuracy: 0.7186 - val_loss: 2.3174 - val_accuracy: 0.4367\n",
      "Epoch 669/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7500 - accuracy: 0.7157 - val_loss: 2.3053 - val_accuracy: 0.4367\n",
      "Epoch 670/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7492 - accuracy: 0.7229 - val_loss: 2.3001 - val_accuracy: 0.4300\n",
      "Epoch 671/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7490 - accuracy: 0.7229 - val_loss: 2.3044 - val_accuracy: 0.4333\n",
      "Epoch 672/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7487 - accuracy: 0.7143 - val_loss: 2.3061 - val_accuracy: 0.4333\n",
      "Epoch 673/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7485 - accuracy: 0.7243 - val_loss: 2.2987 - val_accuracy: 0.4333\n",
      "Epoch 674/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7487 - accuracy: 0.7214 - val_loss: 2.3105 - val_accuracy: 0.4367\n",
      "Epoch 675/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7477 - accuracy: 0.7229 - val_loss: 2.3023 - val_accuracy: 0.4300\n",
      "Epoch 676/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7483 - accuracy: 0.7186 - val_loss: 2.3069 - val_accuracy: 0.4333\n",
      "Epoch 677/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7478 - accuracy: 0.7214 - val_loss: 2.3184 - val_accuracy: 0.4367\n",
      "Epoch 678/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7471 - accuracy: 0.7271 - val_loss: 2.2991 - val_accuracy: 0.4367\n",
      "Epoch 679/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7481 - accuracy: 0.7214 - val_loss: 2.3108 - val_accuracy: 0.4333\n",
      "Epoch 680/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7477 - accuracy: 0.7214 - val_loss: 2.3164 - val_accuracy: 0.4333\n",
      "Epoch 681/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7465 - accuracy: 0.7214 - val_loss: 2.3250 - val_accuracy: 0.4400\n",
      "Epoch 682/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7472 - accuracy: 0.7171 - val_loss: 2.3221 - val_accuracy: 0.4300\n",
      "Epoch 683/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7461 - accuracy: 0.7214 - val_loss: 2.3197 - val_accuracy: 0.4367\n",
      "Epoch 684/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7469 - accuracy: 0.7186 - val_loss: 2.3244 - val_accuracy: 0.4367\n",
      "Epoch 685/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7453 - accuracy: 0.7229 - val_loss: 2.3207 - val_accuracy: 0.4367\n",
      "Epoch 686/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7457 - accuracy: 0.7200 - val_loss: 2.3224 - val_accuracy: 0.4333\n",
      "Epoch 687/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7450 - accuracy: 0.7171 - val_loss: 2.3196 - val_accuracy: 0.4300\n",
      "Epoch 688/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7443 - accuracy: 0.7214 - val_loss: 2.3359 - val_accuracy: 0.4367\n",
      "Epoch 689/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.7455 - accuracy: 0.7200 - val_loss: 2.3163 - val_accuracy: 0.4333\n",
      "Epoch 690/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7443 - accuracy: 0.7200 - val_loss: 2.3319 - val_accuracy: 0.4333\n",
      "Epoch 691/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7440 - accuracy: 0.7186 - val_loss: 2.3302 - val_accuracy: 0.4300\n",
      "Epoch 692/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7433 - accuracy: 0.7214 - val_loss: 2.3317 - val_accuracy: 0.4300\n",
      "Epoch 693/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7434 - accuracy: 0.7243 - val_loss: 2.3300 - val_accuracy: 0.4333\n",
      "Epoch 694/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7427 - accuracy: 0.7229 - val_loss: 2.3345 - val_accuracy: 0.4333\n",
      "Epoch 695/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7425 - accuracy: 0.7214 - val_loss: 2.3369 - val_accuracy: 0.4333\n",
      "Epoch 696/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7422 - accuracy: 0.7243 - val_loss: 2.3563 - val_accuracy: 0.4400\n",
      "Epoch 697/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7417 - accuracy: 0.7286 - val_loss: 2.3522 - val_accuracy: 0.4333\n",
      "Epoch 698/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7419 - accuracy: 0.7200 - val_loss: 2.3384 - val_accuracy: 0.4333\n",
      "Epoch 699/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7415 - accuracy: 0.7214 - val_loss: 2.3404 - val_accuracy: 0.4333\n",
      "Epoch 700/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7412 - accuracy: 0.7286 - val_loss: 2.3399 - val_accuracy: 0.4333\n",
      "Epoch 701/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7408 - accuracy: 0.7257 - val_loss: 2.3451 - val_accuracy: 0.4333\n",
      "Epoch 702/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7407 - accuracy: 0.7200 - val_loss: 2.3430 - val_accuracy: 0.4333\n",
      "Epoch 703/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7399 - accuracy: 0.7229 - val_loss: 2.3472 - val_accuracy: 0.4367\n",
      "Epoch 704/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7410 - accuracy: 0.7243 - val_loss: 2.3507 - val_accuracy: 0.4333\n",
      "Epoch 705/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7398 - accuracy: 0.7257 - val_loss: 2.3466 - val_accuracy: 0.4333\n",
      "Epoch 706/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7399 - accuracy: 0.7243 - val_loss: 2.3306 - val_accuracy: 0.4333\n",
      "Epoch 707/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7399 - accuracy: 0.7257 - val_loss: 2.3487 - val_accuracy: 0.4333\n",
      "Epoch 708/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7391 - accuracy: 0.7229 - val_loss: 2.3437 - val_accuracy: 0.4333\n",
      "Epoch 709/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7391 - accuracy: 0.7229 - val_loss: 2.3513 - val_accuracy: 0.4333\n",
      "Epoch 710/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7388 - accuracy: 0.7257 - val_loss: 2.3700 - val_accuracy: 0.4400\n",
      "Epoch 711/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7388 - accuracy: 0.7300 - val_loss: 2.3617 - val_accuracy: 0.4400\n",
      "Epoch 712/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7383 - accuracy: 0.7229 - val_loss: 2.3434 - val_accuracy: 0.4300\n",
      "Epoch 713/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7384 - accuracy: 0.7243 - val_loss: 2.3523 - val_accuracy: 0.4333\n",
      "Epoch 714/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7381 - accuracy: 0.7271 - val_loss: 2.3504 - val_accuracy: 0.4333\n",
      "Epoch 715/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7378 - accuracy: 0.7257 - val_loss: 2.3459 - val_accuracy: 0.4333\n",
      "Epoch 716/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7377 - accuracy: 0.7243 - val_loss: 2.3637 - val_accuracy: 0.4333\n",
      "Epoch 717/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7373 - accuracy: 0.7271 - val_loss: 2.3626 - val_accuracy: 0.4333\n",
      "Epoch 718/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7370 - accuracy: 0.7257 - val_loss: 2.3411 - val_accuracy: 0.4333\n",
      "Epoch 719/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7365 - accuracy: 0.7300 - val_loss: 2.3762 - val_accuracy: 0.4333\n",
      "Epoch 720/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7367 - accuracy: 0.7243 - val_loss: 2.3607 - val_accuracy: 0.4333\n",
      "Epoch 721/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7358 - accuracy: 0.7229 - val_loss: 2.3741 - val_accuracy: 0.4333\n",
      "Epoch 722/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7363 - accuracy: 0.7314 - val_loss: 2.3746 - val_accuracy: 0.4333\n",
      "Epoch 723/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7358 - accuracy: 0.7286 - val_loss: 2.3682 - val_accuracy: 0.4367\n",
      "Epoch 724/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7356 - accuracy: 0.7257 - val_loss: 2.3608 - val_accuracy: 0.4333\n",
      "Epoch 725/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7355 - accuracy: 0.7271 - val_loss: 2.3731 - val_accuracy: 0.4300\n",
      "Epoch 726/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7352 - accuracy: 0.7271 - val_loss: 2.3740 - val_accuracy: 0.4300\n",
      "Epoch 727/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7345 - accuracy: 0.7314 - val_loss: 2.3883 - val_accuracy: 0.4367\n",
      "Epoch 728/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7346 - accuracy: 0.7300 - val_loss: 2.3748 - val_accuracy: 0.4333\n",
      "Epoch 729/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7341 - accuracy: 0.7214 - val_loss: 2.3789 - val_accuracy: 0.4333\n",
      "Epoch 730/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7344 - accuracy: 0.7271 - val_loss: 2.3665 - val_accuracy: 0.4333\n",
      "Epoch 731/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.7336 - accuracy: 0.7271 - val_loss: 2.3723 - val_accuracy: 0.4300\n",
      "Epoch 732/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.7343 - accuracy: 0.7300 - val_loss: 2.3862 - val_accuracy: 0.4333\n",
      "Epoch 733/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7334 - accuracy: 0.7257 - val_loss: 2.3750 - val_accuracy: 0.4333\n",
      "Epoch 734/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.7295 - accuracy: 0.72 - 0s 109us/step - loss: 0.7334 - accuracy: 0.7257 - val_loss: 2.3848 - val_accuracy: 0.4333\n",
      "Epoch 735/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7334 - accuracy: 0.7243 - val_loss: 2.3768 - val_accuracy: 0.4333\n",
      "Epoch 736/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7323 - accuracy: 0.7257 - val_loss: 2.4101 - val_accuracy: 0.4467\n",
      "Epoch 737/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7327 - accuracy: 0.7300 - val_loss: 2.3622 - val_accuracy: 0.4333\n",
      "Epoch 738/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7317 - accuracy: 0.7271 - val_loss: 2.3866 - val_accuracy: 0.4333\n",
      "Epoch 739/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7320 - accuracy: 0.7314 - val_loss: 2.3670 - val_accuracy: 0.4300\n",
      "Epoch 740/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7328 - accuracy: 0.7271 - val_loss: 2.3800 - val_accuracy: 0.4333\n",
      "Epoch 741/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7319 - accuracy: 0.7257 - val_loss: 2.3772 - val_accuracy: 0.4333\n",
      "Epoch 742/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7312 - accuracy: 0.7286 - val_loss: 2.3981 - val_accuracy: 0.4400\n",
      "Epoch 743/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7318 - accuracy: 0.7286 - val_loss: 2.4001 - val_accuracy: 0.4433\n",
      "Epoch 744/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7313 - accuracy: 0.7271 - val_loss: 2.3921 - val_accuracy: 0.4367\n",
      "Epoch 745/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7315 - accuracy: 0.7300 - val_loss: 2.3996 - val_accuracy: 0.4333\n",
      "Epoch 746/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7304 - accuracy: 0.7286 - val_loss: 2.4093 - val_accuracy: 0.4300\n",
      "Epoch 747/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7305 - accuracy: 0.7286 - val_loss: 2.3969 - val_accuracy: 0.4400\n",
      "Epoch 748/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7309 - accuracy: 0.7314 - val_loss: 2.4108 - val_accuracy: 0.4433\n",
      "Epoch 749/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7308 - accuracy: 0.7300 - val_loss: 2.4145 - val_accuracy: 0.4333\n",
      "Epoch 750/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7301 - accuracy: 0.7300 - val_loss: 2.3996 - val_accuracy: 0.4333\n",
      "Epoch 751/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7301 - accuracy: 0.7286 - val_loss: 2.3884 - val_accuracy: 0.4333\n",
      "Epoch 752/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7291 - accuracy: 0.7300 - val_loss: 2.4036 - val_accuracy: 0.4333\n",
      "Epoch 753/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7289 - accuracy: 0.7314 - val_loss: 2.4188 - val_accuracy: 0.4433\n",
      "Epoch 754/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7277 - accuracy: 0.7271 - val_loss: 2.3886 - val_accuracy: 0.4333\n",
      "Epoch 755/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7294 - accuracy: 0.7286 - val_loss: 2.4073 - val_accuracy: 0.4333\n",
      "Epoch 756/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7284 - accuracy: 0.7286 - val_loss: 2.4225 - val_accuracy: 0.4433\n",
      "Epoch 757/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7286 - accuracy: 0.7286 - val_loss: 2.4171 - val_accuracy: 0.4433\n",
      "Epoch 758/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7281 - accuracy: 0.7300 - val_loss: 2.4145 - val_accuracy: 0.4400\n",
      "Epoch 759/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7278 - accuracy: 0.7271 - val_loss: 2.4253 - val_accuracy: 0.4400\n",
      "Epoch 760/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7272 - accuracy: 0.7314 - val_loss: 2.4029 - val_accuracy: 0.4300\n",
      "Epoch 761/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7281 - accuracy: 0.7286 - val_loss: 2.4225 - val_accuracy: 0.4333\n",
      "Epoch 762/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7272 - accuracy: 0.7271 - val_loss: 2.4029 - val_accuracy: 0.4300\n",
      "Epoch 763/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.7269 - accuracy: 0.7300 - val_loss: 2.4189 - val_accuracy: 0.4300\n",
      "Epoch 764/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7270 - accuracy: 0.7314 - val_loss: 2.4150 - val_accuracy: 0.4300\n",
      "Epoch 765/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7267 - accuracy: 0.7314 - val_loss: 2.4260 - val_accuracy: 0.4433\n",
      "Epoch 766/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7273 - accuracy: 0.7286 - val_loss: 2.4302 - val_accuracy: 0.4333\n",
      "Epoch 767/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.7260 - accuracy: 0.7300 - val_loss: 2.4241 - val_accuracy: 0.4333\n",
      "Epoch 768/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7262 - accuracy: 0.7343 - val_loss: 2.4196 - val_accuracy: 0.4333\n",
      "Epoch 769/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.7260 - accuracy: 0.7300 - val_loss: 2.4237 - val_accuracy: 0.4300\n",
      "Epoch 770/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.7260 - accuracy: 0.7329 - val_loss: 2.4304 - val_accuracy: 0.4300\n",
      "Epoch 771/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.7253 - accuracy: 0.7286 - val_loss: 2.4397 - val_accuracy: 0.4467\n",
      "Epoch 772/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 136us/step - loss: 0.7251 - accuracy: 0.7300 - val_loss: 2.4364 - val_accuracy: 0.4333\n",
      "Epoch 773/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.7242 - accuracy: 0.7329 - val_loss: 2.4287 - val_accuracy: 0.4333\n",
      "Epoch 774/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7235 - accuracy: 0.7329 - val_loss: 2.4226 - val_accuracy: 0.4300\n",
      "Epoch 775/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.7236 - accuracy: 0.7286 - val_loss: 2.4364 - val_accuracy: 0.4300\n",
      "Epoch 776/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7236 - accuracy: 0.7343 - val_loss: 2.4335 - val_accuracy: 0.4433\n",
      "Epoch 777/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7232 - accuracy: 0.7271 - val_loss: 2.4304 - val_accuracy: 0.4333\n",
      "Epoch 778/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7224 - accuracy: 0.7314 - val_loss: 2.4214 - val_accuracy: 0.4300\n",
      "Epoch 779/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7222 - accuracy: 0.7343 - val_loss: 2.4292 - val_accuracy: 0.4333\n",
      "Epoch 780/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.7223 - accuracy: 0.7357 - val_loss: 2.4434 - val_accuracy: 0.4333\n",
      "Epoch 781/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7218 - accuracy: 0.7329 - val_loss: 2.4293 - val_accuracy: 0.4333\n",
      "Epoch 782/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7211 - accuracy: 0.7343 - val_loss: 2.4321 - val_accuracy: 0.4333\n",
      "Epoch 783/3000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 0.7207 - accuracy: 0.7357 - val_loss: 2.4556 - val_accuracy: 0.4467\n",
      "Epoch 784/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7210 - accuracy: 0.7300 - val_loss: 2.4358 - val_accuracy: 0.4333\n",
      "Epoch 785/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7214 - accuracy: 0.7300 - val_loss: 2.4235 - val_accuracy: 0.4333\n",
      "Epoch 786/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7203 - accuracy: 0.7329 - val_loss: 2.4525 - val_accuracy: 0.4400\n",
      "Epoch 787/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7203 - accuracy: 0.7300 - val_loss: 2.4513 - val_accuracy: 0.4333\n",
      "Epoch 788/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7201 - accuracy: 0.7343 - val_loss: 2.4424 - val_accuracy: 0.4333\n",
      "Epoch 789/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7198 - accuracy: 0.7343 - val_loss: 2.4217 - val_accuracy: 0.4333\n",
      "Epoch 790/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7200 - accuracy: 0.7343 - val_loss: 2.4531 - val_accuracy: 0.4333\n",
      "Epoch 791/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7190 - accuracy: 0.7300 - val_loss: 2.4646 - val_accuracy: 0.4400\n",
      "Epoch 792/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7193 - accuracy: 0.7343 - val_loss: 2.4651 - val_accuracy: 0.4400\n",
      "Epoch 793/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7193 - accuracy: 0.7343 - val_loss: 2.4454 - val_accuracy: 0.4433\n",
      "Epoch 794/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7186 - accuracy: 0.7329 - val_loss: 2.4622 - val_accuracy: 0.4433\n",
      "Epoch 795/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.7191 - accuracy: 0.7371 - val_loss: 2.4580 - val_accuracy: 0.4333\n",
      "Epoch 796/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7184 - accuracy: 0.7329 - val_loss: 2.4482 - val_accuracy: 0.4333\n",
      "Epoch 797/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7178 - accuracy: 0.7343 - val_loss: 2.4585 - val_accuracy: 0.4333\n",
      "Epoch 798/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7174 - accuracy: 0.7357 - val_loss: 2.4621 - val_accuracy: 0.4400\n",
      "Epoch 799/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.7171 - accuracy: 0.7357 - val_loss: 2.4592 - val_accuracy: 0.4333\n",
      "Epoch 800/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7178 - accuracy: 0.7357 - val_loss: 2.4689 - val_accuracy: 0.4333\n",
      "Epoch 801/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7175 - accuracy: 0.7357 - val_loss: 2.4607 - val_accuracy: 0.4333\n",
      "Epoch 802/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7172 - accuracy: 0.7357 - val_loss: 2.4559 - val_accuracy: 0.4333\n",
      "Epoch 803/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7170 - accuracy: 0.7343 - val_loss: 2.4689 - val_accuracy: 0.4333\n",
      "Epoch 804/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7168 - accuracy: 0.7357 - val_loss: 2.4574 - val_accuracy: 0.4300\n",
      "Epoch 805/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7160 - accuracy: 0.7329 - val_loss: 2.4695 - val_accuracy: 0.4333\n",
      "Epoch 806/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7159 - accuracy: 0.7343 - val_loss: 2.4953 - val_accuracy: 0.4467\n",
      "Epoch 807/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7160 - accuracy: 0.7329 - val_loss: 2.4759 - val_accuracy: 0.4333\n",
      "Epoch 808/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7155 - accuracy: 0.7329 - val_loss: 2.4620 - val_accuracy: 0.4333\n",
      "Epoch 809/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7153 - accuracy: 0.7386 - val_loss: 2.4782 - val_accuracy: 0.4467\n",
      "Epoch 810/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7158 - accuracy: 0.7343 - val_loss: 2.4710 - val_accuracy: 0.4333\n",
      "Epoch 811/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7154 - accuracy: 0.7357 - val_loss: 2.4755 - val_accuracy: 0.4400\n",
      "Epoch 812/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7148 - accuracy: 0.7357 - val_loss: 2.4531 - val_accuracy: 0.4333\n",
      "Epoch 813/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.7149 - accuracy: 0.7371 - val_loss: 2.4768 - val_accuracy: 0.4333\n",
      "Epoch 814/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.7148 - accuracy: 0.7357 - val_loss: 2.4731 - val_accuracy: 0.4333\n",
      "Epoch 815/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.7140 - accuracy: 0.7386 - val_loss: 2.4817 - val_accuracy: 0.4400\n",
      "Epoch 816/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7144 - accuracy: 0.7357 - val_loss: 2.4751 - val_accuracy: 0.4333\n",
      "Epoch 817/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7141 - accuracy: 0.7371 - val_loss: 2.4643 - val_accuracy: 0.4333\n",
      "Epoch 818/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7139 - accuracy: 0.7357 - val_loss: 2.4654 - val_accuracy: 0.4333\n",
      "Epoch 819/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7134 - accuracy: 0.7371 - val_loss: 2.4721 - val_accuracy: 0.4333\n",
      "Epoch 820/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7137 - accuracy: 0.7329 - val_loss: 2.4943 - val_accuracy: 0.4400\n",
      "Epoch 821/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7132 - accuracy: 0.7357 - val_loss: 2.4908 - val_accuracy: 0.4400\n",
      "Epoch 822/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7131 - accuracy: 0.7343 - val_loss: 2.4798 - val_accuracy: 0.4333\n",
      "Epoch 823/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7131 - accuracy: 0.7343 - val_loss: 2.4786 - val_accuracy: 0.4333\n",
      "Epoch 824/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7128 - accuracy: 0.7371 - val_loss: 2.5017 - val_accuracy: 0.4400\n",
      "Epoch 825/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7126 - accuracy: 0.7371 - val_loss: 2.4816 - val_accuracy: 0.4400\n",
      "Epoch 826/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7128 - accuracy: 0.7343 - val_loss: 2.4893 - val_accuracy: 0.4333\n",
      "Epoch 827/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7124 - accuracy: 0.7386 - val_loss: 2.4965 - val_accuracy: 0.4400\n",
      "Epoch 828/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7125 - accuracy: 0.7343 - val_loss: 2.5023 - val_accuracy: 0.4333\n",
      "Epoch 829/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7115 - accuracy: 0.7386 - val_loss: 2.4911 - val_accuracy: 0.4333\n",
      "Epoch 830/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7114 - accuracy: 0.7343 - val_loss: 2.4963 - val_accuracy: 0.4400\n",
      "Epoch 831/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7115 - accuracy: 0.7386 - val_loss: 2.5064 - val_accuracy: 0.4433\n",
      "Epoch 832/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7112 - accuracy: 0.7357 - val_loss: 2.5266 - val_accuracy: 0.4433\n",
      "Epoch 833/3000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 0.7117 - accuracy: 0.7371 - val_loss: 2.4842 - val_accuracy: 0.4333\n",
      "Epoch 834/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.7113 - accuracy: 0.7371 - val_loss: 2.5037 - val_accuracy: 0.4333\n",
      "Epoch 835/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7108 - accuracy: 0.7400 - val_loss: 2.5074 - val_accuracy: 0.4400\n",
      "Epoch 836/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7113 - accuracy: 0.7386 - val_loss: 2.5037 - val_accuracy: 0.4367\n",
      "Epoch 837/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7104 - accuracy: 0.7371 - val_loss: 2.5185 - val_accuracy: 0.4400\n",
      "Epoch 838/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7102 - accuracy: 0.7371 - val_loss: 2.5116 - val_accuracy: 0.4333\n",
      "Epoch 839/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7099 - accuracy: 0.7386 - val_loss: 2.5011 - val_accuracy: 0.4433\n",
      "Epoch 840/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7100 - accuracy: 0.7371 - val_loss: 2.5193 - val_accuracy: 0.4400\n",
      "Epoch 841/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7095 - accuracy: 0.7371 - val_loss: 2.5307 - val_accuracy: 0.4400\n",
      "Epoch 842/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7099 - accuracy: 0.7343 - val_loss: 2.5137 - val_accuracy: 0.4333\n",
      "Epoch 843/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7090 - accuracy: 0.7386 - val_loss: 2.5354 - val_accuracy: 0.4400\n",
      "Epoch 844/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7095 - accuracy: 0.7400 - val_loss: 2.5087 - val_accuracy: 0.4333\n",
      "Epoch 845/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7093 - accuracy: 0.7386 - val_loss: 2.5036 - val_accuracy: 0.4333\n",
      "Epoch 846/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7090 - accuracy: 0.7343 - val_loss: 2.5255 - val_accuracy: 0.4400\n",
      "Epoch 847/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7089 - accuracy: 0.7371 - val_loss: 2.5094 - val_accuracy: 0.4333\n",
      "Epoch 848/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7089 - accuracy: 0.7386 - val_loss: 2.5267 - val_accuracy: 0.4400\n",
      "Epoch 849/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7088 - accuracy: 0.7357 - val_loss: 2.5187 - val_accuracy: 0.4400\n",
      "Epoch 850/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7081 - accuracy: 0.7386 - val_loss: 2.5076 - val_accuracy: 0.4333\n",
      "Epoch 851/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7083 - accuracy: 0.7386 - val_loss: 2.5156 - val_accuracy: 0.4400\n",
      "Epoch 852/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7079 - accuracy: 0.7386 - val_loss: 2.5167 - val_accuracy: 0.4333\n",
      "Epoch 853/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7074 - accuracy: 0.7386 - val_loss: 2.5361 - val_accuracy: 0.4367\n",
      "Epoch 854/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7076 - accuracy: 0.7386 - val_loss: 2.5331 - val_accuracy: 0.4400\n",
      "Epoch 855/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.7074 - accuracy: 0.7386 - val_loss: 2.5082 - val_accuracy: 0.4333\n",
      "Epoch 856/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.7071 - accuracy: 0.7414 - val_loss: 2.5291 - val_accuracy: 0.4333\n",
      "Epoch 857/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.7070 - accuracy: 0.7400 - val_loss: 2.5275 - val_accuracy: 0.4400\n",
      "Epoch 858/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7068 - accuracy: 0.7386 - val_loss: 2.5315 - val_accuracy: 0.4433\n",
      "Epoch 859/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7066 - accuracy: 0.7400 - val_loss: 2.5420 - val_accuracy: 0.4400\n",
      "Epoch 860/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7063 - accuracy: 0.7386 - val_loss: 2.5330 - val_accuracy: 0.4400\n",
      "Epoch 861/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7063 - accuracy: 0.7400 - val_loss: 2.5378 - val_accuracy: 0.4433\n",
      "Epoch 862/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7065 - accuracy: 0.7371 - val_loss: 2.5276 - val_accuracy: 0.4367\n",
      "Epoch 863/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7058 - accuracy: 0.7386 - val_loss: 2.5489 - val_accuracy: 0.4367\n",
      "Epoch 864/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.7062 - accuracy: 0.7357 - val_loss: 2.5414 - val_accuracy: 0.4367\n",
      "Epoch 865/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7058 - accuracy: 0.7400 - val_loss: 2.5429 - val_accuracy: 0.4367\n",
      "Epoch 866/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7056 - accuracy: 0.7414 - val_loss: 2.5300 - val_accuracy: 0.4333\n",
      "Epoch 867/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7055 - accuracy: 0.7386 - val_loss: 2.5361 - val_accuracy: 0.4433\n",
      "Epoch 868/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7054 - accuracy: 0.7386 - val_loss: 2.5403 - val_accuracy: 0.4400\n",
      "Epoch 869/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7052 - accuracy: 0.7371 - val_loss: 2.5346 - val_accuracy: 0.4333\n",
      "Epoch 870/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.7051 - accuracy: 0.7400 - val_loss: 2.5504 - val_accuracy: 0.4333\n",
      "Epoch 871/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7041 - accuracy: 0.7400 - val_loss: 2.5388 - val_accuracy: 0.4400\n",
      "Epoch 872/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.7043 - accuracy: 0.7371 - val_loss: 2.5473 - val_accuracy: 0.4400\n",
      "Epoch 873/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7045 - accuracy: 0.7414 - val_loss: 2.5574 - val_accuracy: 0.4400\n",
      "Epoch 874/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7047 - accuracy: 0.7400 - val_loss: 2.5485 - val_accuracy: 0.4367\n",
      "Epoch 875/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7044 - accuracy: 0.7400 - val_loss: 2.5470 - val_accuracy: 0.4433\n",
      "Epoch 876/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7043 - accuracy: 0.7400 - val_loss: 2.5691 - val_accuracy: 0.4400\n",
      "Epoch 877/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7036 - accuracy: 0.7386 - val_loss: 2.5686 - val_accuracy: 0.4367\n",
      "Epoch 878/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.7035 - accuracy: 0.7414 - val_loss: 2.5704 - val_accuracy: 0.4367\n",
      "Epoch 879/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.7031 - accuracy: 0.7400 - val_loss: 2.5536 - val_accuracy: 0.4333\n",
      "Epoch 880/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7032 - accuracy: 0.7414 - val_loss: 2.5786 - val_accuracy: 0.4433\n",
      "Epoch 881/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.7035 - accuracy: 0.7400 - val_loss: 2.5477 - val_accuracy: 0.4367\n",
      "Epoch 882/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 91us/step - loss: 0.7026 - accuracy: 0.7400 - val_loss: 2.5540 - val_accuracy: 0.4333\n",
      "Epoch 883/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7029 - accuracy: 0.7386 - val_loss: 2.5602 - val_accuracy: 0.4333\n",
      "Epoch 884/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7025 - accuracy: 0.7400 - val_loss: 2.5567 - val_accuracy: 0.4300\n",
      "Epoch 885/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7024 - accuracy: 0.7400 - val_loss: 2.5621 - val_accuracy: 0.4367\n",
      "Epoch 886/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.7024 - accuracy: 0.7400 - val_loss: 2.5663 - val_accuracy: 0.4400\n",
      "Epoch 887/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7020 - accuracy: 0.7400 - val_loss: 2.5649 - val_accuracy: 0.4400\n",
      "Epoch 888/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.7020 - accuracy: 0.7429 - val_loss: 2.5447 - val_accuracy: 0.4333\n",
      "Epoch 889/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.7024 - accuracy: 0.7386 - val_loss: 2.5676 - val_accuracy: 0.4400\n",
      "Epoch 890/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.7016 - accuracy: 0.7414 - val_loss: 2.5585 - val_accuracy: 0.4333\n",
      "Epoch 891/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7015 - accuracy: 0.7414 - val_loss: 2.5682 - val_accuracy: 0.4400\n",
      "Epoch 892/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.7021 - accuracy: 0.7400 - val_loss: 2.5656 - val_accuracy: 0.4333\n",
      "Epoch 893/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.7013 - accuracy: 0.7400 - val_loss: 2.5649 - val_accuracy: 0.4367\n",
      "Epoch 894/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.7010 - accuracy: 0.7429 - val_loss: 2.5715 - val_accuracy: 0.4367\n",
      "Epoch 895/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7011 - accuracy: 0.7400 - val_loss: 2.5727 - val_accuracy: 0.4400\n",
      "Epoch 896/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.7006 - accuracy: 0.7414 - val_loss: 2.5738 - val_accuracy: 0.4367\n",
      "Epoch 897/3000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 0.7005 - accuracy: 0.7414 - val_loss: 2.5760 - val_accuracy: 0.4400\n",
      "Epoch 898/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.7003 - accuracy: 0.7429 - val_loss: 2.5905 - val_accuracy: 0.4367\n",
      "Epoch 899/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6999 - accuracy: 0.7414 - val_loss: 2.5864 - val_accuracy: 0.4367\n",
      "Epoch 900/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6998 - accuracy: 0.7429 - val_loss: 2.5936 - val_accuracy: 0.4367\n",
      "Epoch 901/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.7003 - accuracy: 0.7429 - val_loss: 2.5762 - val_accuracy: 0.4300\n",
      "Epoch 902/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6997 - accuracy: 0.7414 - val_loss: 2.5817 - val_accuracy: 0.4400\n",
      "Epoch 903/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6989 - accuracy: 0.7414 - val_loss: 2.6128 - val_accuracy: 0.4367\n",
      "Epoch 904/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6999 - accuracy: 0.7414 - val_loss: 2.5834 - val_accuracy: 0.4367\n",
      "Epoch 905/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6993 - accuracy: 0.7371 - val_loss: 2.5924 - val_accuracy: 0.4367\n",
      "Epoch 906/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6990 - accuracy: 0.7400 - val_loss: 2.5820 - val_accuracy: 0.4300\n",
      "Epoch 907/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6984 - accuracy: 0.7414 - val_loss: 2.5935 - val_accuracy: 0.4367\n",
      "Epoch 908/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6995 - accuracy: 0.7386 - val_loss: 2.5858 - val_accuracy: 0.4400\n",
      "Epoch 909/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6992 - accuracy: 0.7414 - val_loss: 2.5941 - val_accuracy: 0.4367\n",
      "Epoch 910/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6987 - accuracy: 0.7414 - val_loss: 2.5917 - val_accuracy: 0.4367\n",
      "Epoch 911/3000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 0.6984 - accuracy: 0.7414 - val_loss: 2.5947 - val_accuracy: 0.4367\n",
      "Epoch 912/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6985 - accuracy: 0.7386 - val_loss: 2.5848 - val_accuracy: 0.4333\n",
      "Epoch 913/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6977 - accuracy: 0.7400 - val_loss: 2.6021 - val_accuracy: 0.4433\n",
      "Epoch 914/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6983 - accuracy: 0.7414 - val_loss: 2.6098 - val_accuracy: 0.4333\n",
      "Epoch 915/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6978 - accuracy: 0.7429 - val_loss: 2.6158 - val_accuracy: 0.4367\n",
      "Epoch 916/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6980 - accuracy: 0.7429 - val_loss: 2.6021 - val_accuracy: 0.4300\n",
      "Epoch 917/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6977 - accuracy: 0.7429 - val_loss: 2.5965 - val_accuracy: 0.4300\n",
      "Epoch 918/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6975 - accuracy: 0.7414 - val_loss: 2.6046 - val_accuracy: 0.4400\n",
      "Epoch 919/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6973 - accuracy: 0.7429 - val_loss: 2.6067 - val_accuracy: 0.4367\n",
      "Epoch 920/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6969 - accuracy: 0.7400 - val_loss: 2.6172 - val_accuracy: 0.4433\n",
      "Epoch 921/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6972 - accuracy: 0.7414 - val_loss: 2.5961 - val_accuracy: 0.4400\n",
      "Epoch 922/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6968 - accuracy: 0.7429 - val_loss: 2.6148 - val_accuracy: 0.4433\n",
      "Epoch 923/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6968 - accuracy: 0.7414 - val_loss: 2.6148 - val_accuracy: 0.4367\n",
      "Epoch 924/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6959 - accuracy: 0.7400 - val_loss: 2.6033 - val_accuracy: 0.4300\n",
      "Epoch 925/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6967 - accuracy: 0.7429 - val_loss: 2.6142 - val_accuracy: 0.4400\n",
      "Epoch 926/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6959 - accuracy: 0.7429 - val_loss: 2.6077 - val_accuracy: 0.4367\n",
      "Epoch 927/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6963 - accuracy: 0.7414 - val_loss: 2.6119 - val_accuracy: 0.4300\n",
      "Epoch 928/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6956 - accuracy: 0.7414 - val_loss: 2.6097 - val_accuracy: 0.4300\n",
      "Epoch 929/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6963 - accuracy: 0.7414 - val_loss: 2.6146 - val_accuracy: 0.4300\n",
      "Epoch 930/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6962 - accuracy: 0.7414 - val_loss: 2.6116 - val_accuracy: 0.4400\n",
      "Epoch 931/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6957 - accuracy: 0.7429 - val_loss: 2.6278 - val_accuracy: 0.4400\n",
      "Epoch 932/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6950 - accuracy: 0.7429 - val_loss: 2.6301 - val_accuracy: 0.4367\n",
      "Epoch 933/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6954 - accuracy: 0.7443 - val_loss: 2.6158 - val_accuracy: 0.4400\n",
      "Epoch 934/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6951 - accuracy: 0.7414 - val_loss: 2.6230 - val_accuracy: 0.4367\n",
      "Epoch 935/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6947 - accuracy: 0.7443 - val_loss: 2.6148 - val_accuracy: 0.4300\n",
      "Epoch 936/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6952 - accuracy: 0.7443 - val_loss: 2.6192 - val_accuracy: 0.4367\n",
      "Epoch 937/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6943 - accuracy: 0.7443 - val_loss: 2.6239 - val_accuracy: 0.4367\n",
      "Epoch 938/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6944 - accuracy: 0.7429 - val_loss: 2.6210 - val_accuracy: 0.4367\n",
      "Epoch 939/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.6944 - accuracy: 0.7414 - val_loss: 2.6124 - val_accuracy: 0.4367\n",
      "Epoch 940/3000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 0.6942 - accuracy: 0.7443 - val_loss: 2.6259 - val_accuracy: 0.4367\n",
      "Epoch 941/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6941 - accuracy: 0.7429 - val_loss: 2.6195 - val_accuracy: 0.4400\n",
      "Epoch 942/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6936 - accuracy: 0.7429 - val_loss: 2.6379 - val_accuracy: 0.4367\n",
      "Epoch 943/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6940 - accuracy: 0.7443 - val_loss: 2.6352 - val_accuracy: 0.4367\n",
      "Epoch 944/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6940 - accuracy: 0.7429 - val_loss: 2.6258 - val_accuracy: 0.4400\n",
      "Epoch 945/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6936 - accuracy: 0.7443 - val_loss: 2.6221 - val_accuracy: 0.4367\n",
      "Epoch 946/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6926 - accuracy: 0.7443 - val_loss: 2.6336 - val_accuracy: 0.4300\n",
      "Epoch 947/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6929 - accuracy: 0.7429 - val_loss: 2.6567 - val_accuracy: 0.4333\n",
      "Epoch 948/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6932 - accuracy: 0.7429 - val_loss: 2.6326 - val_accuracy: 0.4367\n",
      "Epoch 949/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6928 - accuracy: 0.7443 - val_loss: 2.6374 - val_accuracy: 0.4367\n",
      "Epoch 950/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6930 - accuracy: 0.7443 - val_loss: 2.6389 - val_accuracy: 0.4367\n",
      "Epoch 951/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6925 - accuracy: 0.7429 - val_loss: 2.6395 - val_accuracy: 0.4367\n",
      "Epoch 952/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.6927 - accuracy: 0.7414 - val_loss: 2.6385 - val_accuracy: 0.4400\n",
      "Epoch 953/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6925 - accuracy: 0.7429 - val_loss: 2.6682 - val_accuracy: 0.4400\n",
      "Epoch 954/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6928 - accuracy: 0.7429 - val_loss: 2.6653 - val_accuracy: 0.4400\n",
      "Epoch 955/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6924 - accuracy: 0.7443 - val_loss: 2.6517 - val_accuracy: 0.4400\n",
      "Epoch 956/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6923 - accuracy: 0.7443 - val_loss: 2.6679 - val_accuracy: 0.4400\n",
      "Epoch 957/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6923 - accuracy: 0.7443 - val_loss: 2.6624 - val_accuracy: 0.4400\n",
      "Epoch 958/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6922 - accuracy: 0.7443 - val_loss: 2.6575 - val_accuracy: 0.4367\n",
      "Epoch 959/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6916 - accuracy: 0.7443 - val_loss: 2.6466 - val_accuracy: 0.4367\n",
      "Epoch 960/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.6914 - accuracy: 0.7443 - val_loss: 2.6582 - val_accuracy: 0.4400\n",
      "Epoch 961/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6913 - accuracy: 0.7457 - val_loss: 2.6474 - val_accuracy: 0.4400\n",
      "Epoch 962/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6909 - accuracy: 0.7443 - val_loss: 2.6829 - val_accuracy: 0.4333\n",
      "Epoch 963/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6915 - accuracy: 0.7443 - val_loss: 2.6630 - val_accuracy: 0.4400\n",
      "Epoch 964/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6906 - accuracy: 0.7443 - val_loss: 2.6632 - val_accuracy: 0.4400\n",
      "Epoch 965/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6912 - accuracy: 0.7429 - val_loss: 2.6526 - val_accuracy: 0.4367\n",
      "Epoch 966/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6902 - accuracy: 0.7443 - val_loss: 2.6536 - val_accuracy: 0.4367\n",
      "Epoch 967/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6904 - accuracy: 0.7429 - val_loss: 2.6624 - val_accuracy: 0.4400\n",
      "Epoch 968/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6900 - accuracy: 0.7457 - val_loss: 2.6569 - val_accuracy: 0.4367\n",
      "Epoch 969/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6902 - accuracy: 0.7429 - val_loss: 2.6549 - val_accuracy: 0.4400\n",
      "Epoch 970/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6907 - accuracy: 0.7429 - val_loss: 2.6578 - val_accuracy: 0.4400\n",
      "Epoch 971/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6900 - accuracy: 0.7429 - val_loss: 2.6726 - val_accuracy: 0.4367\n",
      "Epoch 972/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6900 - accuracy: 0.7429 - val_loss: 2.6683 - val_accuracy: 0.4367\n",
      "Epoch 973/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6898 - accuracy: 0.7414 - val_loss: 2.6630 - val_accuracy: 0.4400\n",
      "Epoch 974/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6896 - accuracy: 0.7443 - val_loss: 2.6789 - val_accuracy: 0.4367\n",
      "Epoch 975/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6901 - accuracy: 0.7429 - val_loss: 2.6673 - val_accuracy: 0.4400\n",
      "Epoch 976/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.6893 - accuracy: 0.7429 - val_loss: 2.6544 - val_accuracy: 0.4400\n",
      "Epoch 977/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6894 - accuracy: 0.7429 - val_loss: 2.6661 - val_accuracy: 0.4400\n",
      "Epoch 978/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6889 - accuracy: 0.7443 - val_loss: 2.6628 - val_accuracy: 0.4400\n",
      "Epoch 979/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6895 - accuracy: 0.7457 - val_loss: 2.6768 - val_accuracy: 0.4400\n",
      "Epoch 980/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6886 - accuracy: 0.7429 - val_loss: 2.6794 - val_accuracy: 0.4367\n",
      "Epoch 981/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.6885 - accuracy: 0.7443 - val_loss: 2.6630 - val_accuracy: 0.4400\n",
      "Epoch 982/3000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 0.6885 - accuracy: 0.7443 - val_loss: 2.6890 - val_accuracy: 0.4367\n",
      "Epoch 983/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6883 - accuracy: 0.7443 - val_loss: 2.6911 - val_accuracy: 0.4333\n",
      "Epoch 984/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6882 - accuracy: 0.7457 - val_loss: 2.6721 - val_accuracy: 0.4400\n",
      "Epoch 985/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6880 - accuracy: 0.7457 - val_loss: 2.6588 - val_accuracy: 0.4367\n",
      "Epoch 986/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.6880 - accuracy: 0.7457 - val_loss: 2.6814 - val_accuracy: 0.4367\n",
      "Epoch 987/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6880 - accuracy: 0.7429 - val_loss: 2.6739 - val_accuracy: 0.4400\n",
      "Epoch 988/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6880 - accuracy: 0.7443 - val_loss: 2.6886 - val_accuracy: 0.4400\n",
      "Epoch 989/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6877 - accuracy: 0.7457 - val_loss: 2.6883 - val_accuracy: 0.4367\n",
      "Epoch 990/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6873 - accuracy: 0.7429 - val_loss: 2.6733 - val_accuracy: 0.4433\n",
      "Epoch 991/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6874 - accuracy: 0.7443 - val_loss: 2.6793 - val_accuracy: 0.4367\n",
      "Epoch 992/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 111us/step - loss: 0.6871 - accuracy: 0.7443 - val_loss: 2.6670 - val_accuracy: 0.4333\n",
      "Epoch 993/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6873 - accuracy: 0.7429 - val_loss: 2.6850 - val_accuracy: 0.4367\n",
      "Epoch 994/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6867 - accuracy: 0.7429 - val_loss: 2.6780 - val_accuracy: 0.4433\n",
      "Epoch 995/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6866 - accuracy: 0.7429 - val_loss: 2.7119 - val_accuracy: 0.4300\n",
      "Epoch 996/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6874 - accuracy: 0.7443 - val_loss: 2.6943 - val_accuracy: 0.4367\n",
      "Epoch 997/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.6866 - accuracy: 0.7429 - val_loss: 2.6803 - val_accuracy: 0.4400\n",
      "Epoch 998/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6864 - accuracy: 0.7471 - val_loss: 2.6823 - val_accuracy: 0.4400\n",
      "Epoch 999/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6862 - accuracy: 0.7471 - val_loss: 2.6977 - val_accuracy: 0.4367\n",
      "Epoch 1000/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6863 - accuracy: 0.7429 - val_loss: 2.6874 - val_accuracy: 0.4367\n",
      "Epoch 1001/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6865 - accuracy: 0.7429 - val_loss: 2.6870 - val_accuracy: 0.4400\n",
      "Epoch 1002/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.6860 - accuracy: 0.7429 - val_loss: 2.7069 - val_accuracy: 0.4367\n",
      "Epoch 1003/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6859 - accuracy: 0.7443 - val_loss: 2.7094 - val_accuracy: 0.4333\n",
      "Epoch 1004/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6858 - accuracy: 0.7457 - val_loss: 2.7184 - val_accuracy: 0.4300\n",
      "Epoch 1005/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6855 - accuracy: 0.7429 - val_loss: 2.7144 - val_accuracy: 0.4267\n",
      "Epoch 1006/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6855 - accuracy: 0.7443 - val_loss: 2.6953 - val_accuracy: 0.4400\n",
      "Epoch 1007/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6851 - accuracy: 0.7457 - val_loss: 2.7058 - val_accuracy: 0.4300\n",
      "Epoch 1008/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6851 - accuracy: 0.7443 - val_loss: 2.7097 - val_accuracy: 0.4333\n",
      "Epoch 1009/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6851 - accuracy: 0.7443 - val_loss: 2.7060 - val_accuracy: 0.4300\n",
      "Epoch 1010/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.6852 - accuracy: 0.7443 - val_loss: 2.6991 - val_accuracy: 0.4400\n",
      "Epoch 1011/3000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 0.6850 - accuracy: 0.7443 - val_loss: 2.6961 - val_accuracy: 0.4400\n",
      "Epoch 1012/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6846 - accuracy: 0.7429 - val_loss: 2.7166 - val_accuracy: 0.4267\n",
      "Epoch 1013/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6847 - accuracy: 0.7457 - val_loss: 2.7112 - val_accuracy: 0.4367\n",
      "Epoch 1014/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6841 - accuracy: 0.7457 - val_loss: 2.7121 - val_accuracy: 0.4367\n",
      "Epoch 1015/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6842 - accuracy: 0.7443 - val_loss: 2.7110 - val_accuracy: 0.4367\n",
      "Epoch 1016/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6840 - accuracy: 0.7443 - val_loss: 2.7252 - val_accuracy: 0.4333\n",
      "Epoch 1017/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6839 - accuracy: 0.7443 - val_loss: 2.6982 - val_accuracy: 0.4433\n",
      "Epoch 1018/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6836 - accuracy: 0.7471 - val_loss: 2.6998 - val_accuracy: 0.4367\n",
      "Epoch 1019/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6839 - accuracy: 0.7429 - val_loss: 2.7177 - val_accuracy: 0.4367\n",
      "Epoch 1020/3000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 0.6837 - accuracy: 0.7457 - val_loss: 2.7072 - val_accuracy: 0.4300\n",
      "Epoch 1021/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6835 - accuracy: 0.7443 - val_loss: 2.7446 - val_accuracy: 0.4333\n",
      "Epoch 1022/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.6834 - accuracy: 0.7443 - val_loss: 2.7321 - val_accuracy: 0.4367\n",
      "Epoch 1023/3000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 0.6833 - accuracy: 0.7443 - val_loss: 2.7107 - val_accuracy: 0.4300\n",
      "Epoch 1024/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6835 - accuracy: 0.7457 - val_loss: 2.7172 - val_accuracy: 0.4333\n",
      "Epoch 1025/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6832 - accuracy: 0.7443 - val_loss: 2.7170 - val_accuracy: 0.4333\n",
      "Epoch 1026/3000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 0.6828 - accuracy: 0.7443 - val_loss: 2.7228 - val_accuracy: 0.4367\n",
      "Epoch 1027/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6823 - accuracy: 0.7471 - val_loss: 2.7287 - val_accuracy: 0.4367\n",
      "Epoch 1028/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6828 - accuracy: 0.7429 - val_loss: 2.6986 - val_accuracy: 0.4333\n",
      "Epoch 1029/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6824 - accuracy: 0.7443 - val_loss: 2.7080 - val_accuracy: 0.4367\n",
      "Epoch 1030/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6828 - accuracy: 0.7429 - val_loss: 2.7233 - val_accuracy: 0.4367\n",
      "Epoch 1031/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.6825 - accuracy: 0.7443 - val_loss: 2.7327 - val_accuracy: 0.4367\n",
      "Epoch 1032/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6821 - accuracy: 0.7457 - val_loss: 2.7313 - val_accuracy: 0.4300\n",
      "Epoch 1033/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6822 - accuracy: 0.7486 - val_loss: 2.7200 - val_accuracy: 0.4367\n",
      "Epoch 1034/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6821 - accuracy: 0.7457 - val_loss: 2.7407 - val_accuracy: 0.4267\n",
      "Epoch 1035/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6816 - accuracy: 0.7429 - val_loss: 2.7519 - val_accuracy: 0.4267\n",
      "Epoch 1036/3000\n",
      "700/700 [==============================] - 0s 91us/step - loss: 0.6819 - accuracy: 0.7486 - val_loss: 2.7329 - val_accuracy: 0.4333\n",
      "Epoch 1037/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.6817 - accuracy: 0.7457 - val_loss: 2.7500 - val_accuracy: 0.4267\n",
      "Epoch 1038/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6815 - accuracy: 0.7457 - val_loss: 2.7233 - val_accuracy: 0.4300\n",
      "Epoch 1039/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6816 - accuracy: 0.7443 - val_loss: 2.7416 - val_accuracy: 0.4333\n",
      "Epoch 1040/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6818 - accuracy: 0.7471 - val_loss: 2.7427 - val_accuracy: 0.4300\n",
      "Epoch 1041/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6808 - accuracy: 0.7457 - val_loss: 2.7486 - val_accuracy: 0.4367\n",
      "Epoch 1042/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6812 - accuracy: 0.7443 - val_loss: 2.7323 - val_accuracy: 0.4300\n",
      "Epoch 1043/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6811 - accuracy: 0.7443 - val_loss: 2.7276 - val_accuracy: 0.4367\n",
      "Epoch 1044/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6807 - accuracy: 0.7471 - val_loss: 2.7352 - val_accuracy: 0.4367\n",
      "Epoch 1045/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6803 - accuracy: 0.7443 - val_loss: 2.7419 - val_accuracy: 0.4300\n",
      "Epoch 1046/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6805 - accuracy: 0.7443 - val_loss: 2.7414 - val_accuracy: 0.4367\n",
      "Epoch 1047/3000\n",
      " 10/700 [..............................] - ETA: 0s - loss: 0.2989 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-2b60e422e4f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(xtrain,ytrain,epochs=3000,batch_size=10, validation_data=(xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-2d3d41098766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0macc_ax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.legend(loc='lower left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 18us/step\n",
      "cost : 0.22991833183318378\n",
      "accuracy : 0.9348000288009644\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(xtest,ytest,batch_size=32)\n",
    "print('cost : '+str(res[0]))\n",
    "print('accuracy : '+str(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## callback() : 특정 상황에서 함수 내에서 또다른 함수 호출\n",
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.2591 - accuracy: 0.5129 - val_loss: 3.3829 - val_accuracy: 0.2433\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.2582 - accuracy: 0.5114 - val_loss: 3.4305 - val_accuracy: 0.2400\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(xtrain,ytrain,epochs=3000,batch_size=10, validation_data=(xval,yval), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.legend(loc='lower left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.6806 - accuracy: 0.7457 - val_loss: 2.7458 - val_accuracy: 0.4367\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 0.6807 - accuracy: 0.7486 - val_loss: 2.7392 - val_accuracy: 0.4367\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6798 - accuracy: 0.7500 - val_loss: 2.7606 - val_accuracy: 0.4300\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6803 - accuracy: 0.7471 - val_loss: 2.7517 - val_accuracy: 0.4300\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6800 - accuracy: 0.7471 - val_loss: 2.7631 - val_accuracy: 0.4300\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6800 - accuracy: 0.7471 - val_loss: 2.7459 - val_accuracy: 0.4367\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 0.6797 - accuracy: 0.7443 - val_loss: 2.7481 - val_accuracy: 0.4300\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6796 - accuracy: 0.7471 - val_loss: 2.7583 - val_accuracy: 0.4300\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6791 - accuracy: 0.7471 - val_loss: 2.7591 - val_accuracy: 0.4300\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6801 - accuracy: 0.7500 - val_loss: 2.7421 - val_accuracy: 0.4333\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 0.6794 - accuracy: 0.7486 - val_loss: 2.7496 - val_accuracy: 0.4367\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.6792 - accuracy: 0.7457 - val_loss: 2.7336 - val_accuracy: 0.4333\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6790 - accuracy: 0.7486 - val_loss: 2.7392 - val_accuracy: 0.4367\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 0.6797 - accuracy: 0.7486 - val_loss: 2.7567 - val_accuracy: 0.4367\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.6787 - accuracy: 0.7486 - val_loss: 2.7656 - val_accuracy: 0.4300\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 0.6786 - accuracy: 0.7486 - val_loss: 2.7716 - val_accuracy: 0.4267\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6787 - accuracy: 0.7471 - val_loss: 2.7635 - val_accuracy: 0.4300\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6783 - accuracy: 0.7471 - val_loss: 2.7663 - val_accuracy: 0.4300\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6785 - accuracy: 0.7471 - val_loss: 2.7717 - val_accuracy: 0.4333\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6783 - accuracy: 0.7486 - val_loss: 2.7618 - val_accuracy: 0.4300\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 0.6783 - accuracy: 0.7471 - val_loss: 2.7728 - val_accuracy: 0.4267\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.80 - 0s 96us/step - loss: 0.6780 - accuracy: 0.7471 - val_loss: 2.7524 - val_accuracy: 0.4300\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6779 - accuracy: 0.7486 - val_loss: 2.7676 - val_accuracy: 0.4300\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6783 - accuracy: 0.7500 - val_loss: 2.7729 - val_accuracy: 0.4267\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6773 - accuracy: 0.7500 - val_loss: 2.7633 - val_accuracy: 0.4300\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 0.6776 - accuracy: 0.7514 - val_loss: 2.7653 - val_accuracy: 0.4333\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 0.6775 - accuracy: 0.7500 - val_loss: 2.8049 - val_accuracy: 0.4300\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6779 - accuracy: 0.7529 - val_loss: 2.7694 - val_accuracy: 0.4300\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 0.6769 - accuracy: 0.7514 - val_loss: 2.7893 - val_accuracy: 0.4300\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 0.6773 - accuracy: 0.7529 - val_loss: 2.7672 - val_accuracy: 0.4233\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6772 - accuracy: 0.7557 - val_loss: 2.7817 - val_accuracy: 0.4300\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 0.6762 - accuracy: 0.7514 - val_loss: 2.7766 - val_accuracy: 0.4233\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 0.6767 - accuracy: 0.7486 - val_loss: 2.7831 - val_accuracy: 0.4267\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 0.6764 - accuracy: 0.7529 - val_loss: 2.7725 - val_accuracy: 0.4300\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 0.6768 - accuracy: 0.7514 - val_loss: 2.7840 - val_accuracy: 0.4267\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 0.6763 - accuracy: 0.7529 - val_loss: 2.7817 - val_accuracy: 0.4300\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 0.6762 - accuracy: 0.7543 - val_loss: 2.7728 - val_accuracy: 0.4267\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 0.6754 - accuracy: 0.7514 - val_loss: 2.7592 - val_accuracy: 0.4233\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 0.6756 - accuracy: 0.7543 - val_loss: 2.7967 - val_accuracy: 0.4267\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 0.6757 - accuracy: 0.7529 - val_loss: 2.7932 - val_accuracy: 0.4267\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 0.6755 - accuracy: 0.7500 - val_loss: 2.7822 - val_accuracy: 0.4300\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 0.6750 - accuracy: 0.7529 - val_loss: 2.8034 - val_accuracy: 0.4267\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=30)\n",
    "\n",
    "hist = model.fit(xtrain,ytrain,epochs=3000,batch_size=10, validation_data=(xval,yval), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'r',label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'g',label='val acc')\n",
    "\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "loss_ax.legend(loc='upper left')\n",
    "loss_ax.legend(loc='lower left')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "path = r'C:\\\\Users\\\\student\\\\Desktop\\\\dataset\\\\python\\\\data'\n",
    "\n",
    "data = np.loadtxt(path+'\\\\ThoraricSurgery.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470, 18)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:,0:17]\n",
    "y = data[:,17]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=17,  activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "470/470 [==============================] - 0s 283us/step - loss: 0.6499 - accuracy: 0.3234\n",
      "Epoch 2/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1499 - accuracy: 0.8489\n",
      "Epoch 3/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1485 - accuracy: 0.8511\n",
      "Epoch 4/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1482 - accuracy: 0.8511\n",
      "Epoch 5/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 6/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 9/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1480 - accuracy: 0.8511\n",
      "Epoch 10/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1474 - accuracy: 0.8532\n",
      "Epoch 11/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 12/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1476 - accuracy: 0.8511\n",
      "Epoch 13/30\n",
      "470/470 [==============================] - 0s 87us/step - loss: 0.1483 - accuracy: 0.8511\n",
      "Epoch 14/30\n",
      "470/470 [==============================] - 0s 98us/step - loss: 0.1473 - accuracy: 0.8532\n",
      "Epoch 15/30\n",
      "470/470 [==============================] - 0s 100us/step - loss: 0.1477 - accuracy: 0.8532\n",
      "Epoch 16/30\n",
      "470/470 [==============================] - 0s 109us/step - loss: 0.1473 - accuracy: 0.8532\n",
      "Epoch 17/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1479 - accuracy: 0.8511\n",
      "Epoch 18/30\n",
      "470/470 [==============================] - 0s 119us/step - loss: 0.1475 - accuracy: 0.8511\n",
      "Epoch 19/30\n",
      "470/470 [==============================] - 0s 123us/step - loss: 0.1477 - accuracy: 0.8511\n",
      "Epoch 20/30\n",
      "470/470 [==============================] - 0s 104us/step - loss: 0.1481 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1473 - accuracy: 0.8511\n",
      "Epoch 22/30\n",
      "470/470 [==============================] - 0s 89us/step - loss: 0.1482 - accuracy: 0.8489\n",
      "Epoch 23/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 24/30\n",
      "470/470 [==============================] - 0s 83us/step - loss: 0.1488 - accuracy: 0.8511\n",
      "Epoch 25/30\n",
      "470/470 [==============================] - 0s 81us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 26/30\n",
      "470/470 [==============================] - 0s 79us/step - loss: 0.1483 - accuracy: 0.8511\n",
      "Epoch 27/30\n",
      "470/470 [==============================] - 0s 94us/step - loss: 0.1469 - accuracy: 0.8511\n",
      "Epoch 28/30\n",
      "470/470 [==============================] - 0s 94us/step - loss: 0.1464 - accuracy: 0.8532\n",
      "Epoch 29/30\n",
      "470/470 [==============================] - 0s 85us/step - loss: 0.1486 - accuracy: 0.8511\n",
      "Epoch 30/30\n",
      "470/470 [==============================] - 0s 91us/step - loss: 0.1482 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19b86465508>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 102us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14693006873130798, 0.8510638475418091]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
